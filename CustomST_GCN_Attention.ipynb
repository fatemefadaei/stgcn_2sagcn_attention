{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "dwiuI7pedVzp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6b5c585-9617-47ed-d397-a69f760c7f1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "rwUrefn04Vjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Use CUDA:', torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bx-2j-X4XC4",
        "outputId": "e2dde15b-56d4-4869-f655-73102ec644ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use CUDA: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 123\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.use_deterministic_algorithms = True"
      ],
      "metadata": {
        "id": "nlsCRsXu4ZAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reshape_instance(ins):\n",
        "  _,size,_,_=ins.shape\n",
        "  return ins.reshape(3,size,25)\n"
      ],
      "metadata": {
        "id": "WixQu-kpLiWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_clip(data , length=300):\n",
        "  for item_iter in range(len(data)):\n",
        "    if data[item_iter].shape[1]>length:\n",
        "      data[item_iter]= data[item_iter][:,:length,:]\n",
        "  return data"
      ],
      "metadata": {
        "id": "GuELNH8H5lJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading Dataset pickles"
      ],
      "metadata": {
        "id": "TAYeKd9fzZju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('/content/drive/MyDrive/Park/train_3d.pkl', 'rb') as f:\n",
        "    train_data = pickle.load(f)\n",
        "    # train_label = [int(i['label']/10) for i in train_data]\n",
        "    train_label = [i['label'] for i in train_data]\n",
        "    print(train_label[:10])\n",
        "    train_data = [reshape_instance(i['keypoint']) for i in train_data]\n",
        "\n",
        "with open('/content/drive/MyDrive/Park/test_3d.pkl', 'rb') as f:\n",
        "    test_data = pickle.load(f)\n",
        "    # test_label = [int(i['label']/10) for i in test_data]\n",
        "    test_label = [i['label'] for i in test_data]\n",
        "    print(test_label[:10])\n",
        "    test_data = [reshape_instance(i['keypoint']) for i in test_data]\n",
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/Park/val_3d.pkl', 'rb') as f:\n",
        "    val_data = pickle.load(f)\n",
        "    # val_label = [int(i['label']/10) for i in val_data]\n",
        "    val_label = [i['label'] for i in val_data]\n",
        "    print(val_label[:10])\n",
        "    val_data = [reshape_instance(i['keypoint']) for i in val_data]\n",
        "\n",
        "train_data = crop_clip(train_data)\n",
        "test_data = crop_clip(test_data)\n",
        "val_data = crop_clip(val_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7lc0LCAGzFr",
        "outputId": "831b7353-4d64-4a91-bb92-d7a139fd397f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[71, 24, 87, 93, 69, 51, 21, 79, 36, 79]\n",
            "[21, 63, 87, 1, 2, 59, 30, 16, 8, 26]\n",
            "[5, 9, 52, 93, 4, 71, 59, 13, 7, 87]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max(train_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQbp4QbOJtmd",
        "outputId": "fd65c3f0-7c10-4d8e-a887-14c7841ea47a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining collator and feeder"
      ],
      "metadata": {
        "id": "YrzO20amz8th"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import sequence\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "class MyCollator(object):   # makes data on each batch, same in size(length) here length will be at most 300.\n",
        "    def __init__(self,test=False,percentile=4750):\n",
        "        self.test = test\n",
        "        self.percentile = percentile\n",
        "    def __call__(self, batch):\n",
        "        max_len = 300 # default max len\n",
        "        max_len2 = max([x[0].shape[2] for x in batch]) # max len of all instances\n",
        "        batch = sorted(batch, key=lambda x: x[0].shape[1], reverse=True) # sort data of batch based on length\n",
        "        target = [item[1] for item in batch]# list of labels\n",
        "        data = [torch.Tensor(item[0]) for item in batch]# list of data\n",
        "        padded_batch = [torch.nn.functional.pad(torch.Tensor(gif[0]), ( 0,0,max_len - gif[0].shape[1], 0)) for gif in batch] # make data the same length here\n",
        "        return [torch.stack(padded_batch),target] # concat padded_data and labels as new batch. now the model will be error free\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "u0me7XrAgq1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Feeder(torch.utils.data.Dataset): # feeds data to model\n",
        "  def __init__(self, data, label):\n",
        "      super().__init__()\n",
        "      self.label = label\n",
        "      self.data = data\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.label)\n",
        "\n",
        "  def __iter__(self):\n",
        "      return self\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "      data = np.array(self.data[index])\n",
        "      label = self.label[index]\n",
        "\n",
        "      return data, label"
      ],
      "metadata": {
        "id": "Asb7794y4dys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining Graph to load data in the way ntu+rgb D models give it to action recongnition model"
      ],
      "metadata": {
        "id": "WOpHygT-zq-T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFV6MAuFds7V"
      },
      "outputs": [],
      "source": [
        "class Graph():\n",
        "  def __init__(self, hop_size, strategy):\n",
        "    self.get_edge()\n",
        "\n",
        "    self.hop_size = hop_size # nodes to pass in each traverse\n",
        "    self.hop_dis = self.get_hop_distance(self.num_node, self.edge, hop_size=hop_size)\n",
        "\n",
        "    self.get_adjacency(strategy)\n",
        "\n",
        "  def __str__(self):\n",
        "    return self.A\n",
        "\n",
        "  def get_edge(self): # get connected edges in this graph\n",
        "    self.num_node = 25 # its based on the data, experimental\n",
        "    self_link = [(i, i) for i in range(self.num_node)] #edges to the nodes themselves\n",
        "    neighbor_base = [(1, 2), (2, 21), (3, 21), (4, 3), (5, 21), # Main nodes, its based on the data, experimental\n",
        "                      (6, 5), (7, 6), (8, 7), (9, 21), (10, 9),\n",
        "                      (11, 10), (12, 11), (13, 1), (14, 13), (15, 14),\n",
        "                      (16, 15), (17, 1), (18, 17), (19, 18), (20, 19),\n",
        "                      (22, 23), (23, 8), (24, 25), (25, 12)]\n",
        "    neighbor_link = [(i - 1, j - 1) for (i, j) in neighbor_base] # edges to neighbors of the main nodes, its based on the data, experimental\n",
        "    self.self_link = self_link\n",
        "    self.neighbor_link = neighbor_link\n",
        "    self.edge = self_link + neighbor_link # all the edges\n",
        "    self.center = 21 - 1     # central node\n",
        "\n",
        "  def get_adjacency(self, strategy):\n",
        "    valid_hop = range(0, self.hop_size + 1, 1) # how many nodes to traverse\n",
        "    adjacency = np.zeros((self.num_node, self.num_node)) # builds a matrix\n",
        "    for hop in valid_hop:\n",
        "        adjacency[self.hop_dis == hop] = 1 # mark the traverse\n",
        "    normalize_adjacency = self.normalize_digraph(adjacency) # normalization  https://coresignal.com/blog/data-normalization/#:~:text=The%20main%20objective%20of%20database,increase%20security%2C%20and%20lessen%20costs.\n",
        "\n",
        "    if strategy == 'spatial': # spatial technique\n",
        "\n",
        "    # \"\"\"traverses the graph from the central node (root) to a fixed distance (hop size) until it reaches closure.(close)\n",
        "    # this travers makes a circle in the graph, like a domain where we expect main concept of the data,\n",
        "    # for example if the purpose was to find cars, the central node would be somewhere in street, and the domain would be a\n",
        "    # circle in street, all other places would be less important and called (further)\"\"\"\n",
        "\n",
        "      A = []\n",
        "      for hop in valid_hop:\n",
        "          a_root = np.zeros((self.num_node, self.num_node))\n",
        "          a_close = np.zeros((self.num_node, self.num_node))\n",
        "          a_further = np.zeros((self.num_node, self.num_node))\n",
        "          for i in range(self.num_node):\n",
        "              for j in range(self.num_node):\n",
        "                  if self.hop_dis[j, i] == hop:\n",
        "                      if self.hop_dis[j, self.center] == self.hop_dis[\n",
        "                              i, self.center]:\n",
        "                          a_root[j, i] = normalize_adjacency[j, i]\n",
        "                      elif self.hop_dis[j, self.center] > self.hop_dis[\n",
        "                              i, self.center]:\n",
        "                          a_close[j, i] = normalize_adjacency[j, i]\n",
        "                      else:\n",
        "                          a_further[j, i] = normalize_adjacency[j, i]\n",
        "          if hop == 0:\n",
        "              A.append(a_root)\n",
        "          else:\n",
        "              A.append(a_root + a_close)\n",
        "              A.append(a_further)\n",
        "      A = np.stack(A)\n",
        "      self.A = A\n",
        "    elif strategy == 'agcn':\n",
        "      \"\"\"\n",
        "        this time makes a matrix of the nodes, and analyzes these nodes connections\n",
        "      \"\"\"\n",
        "      A = []\n",
        "      link_mat = self.edge2mat(self.self_link, self.num_node) #matrix of connections\n",
        "      In = self.normalize_digraph(self.edge2mat(self.neighbor_link, self.num_node)) #normalization of graph\n",
        "      outward = [(j, i) for (i, j) in self.neighbor_link] #connection of each node\n",
        "      Out = self.normalize_digraph(self.edge2mat(outward, self.num_node)) #normalization\n",
        "      A = np.stack((link_mat, In, Out)) # concat of all info for future use like , connections (link_mat),graph(IN), OUT (connection of each edge)\n",
        "      self.A = A\n",
        "    else:\n",
        "        raise ValueError('Do Not Exist This Strategy')\n",
        "\n",
        "  def get_hop_distance(self, num_node, edge, hop_size): # traverse distance\n",
        "    A = np.zeros((num_node, num_node))\n",
        "    for i, j in edge:\n",
        "        A[j, i] = 1\n",
        "        A[i, j] = 1\n",
        "    hop_dis = np.zeros((num_node, num_node)) + np.inf\n",
        "    transfer_mat = [np.linalg.matrix_power(A, d) for d in range(hop_size + 1)]\n",
        "    arrive_mat = (np.stack(transfer_mat) > 0)\n",
        "    for d in range(hop_size, -1, -1):\n",
        "        hop_dis[arrive_mat[d]] = d\n",
        "    return hop_dis\n",
        "\n",
        "  def normalize_digraph(self, A): # normalization\n",
        "    Dl = np.sum(A, 0)\n",
        "    num_node = A.shape[0]\n",
        "    Dn = np.zeros((num_node, num_node))\n",
        "    for i in range(num_node):\n",
        "        if Dl[i] > 0:\n",
        "            Dn[i, i] = Dl[i]**(-1)\n",
        "    DAD = np.dot(A, Dn)\n",
        "    return DAD\n",
        "\n",
        "  def edge2mat(self, link, num_node): # matrix of edges\n",
        "    A = np.zeros((num_node, num_node))\n",
        "    for i, j in link:\n",
        "        A[j, i] = 1\n",
        "    return A"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attention Module class"
      ],
      "metadata": {
        "id": "1mgKTu4wzOKU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, in_channels, reduction=16):\n",
        "        super(ChannelAttention, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1) # adaptiveavgpool2d reduces tensor dimensions to (b, c, 1, 1)\n",
        "\n",
        "\n",
        "        self.fc = nn.Sequential(# fully connected layers to learn channel-wise attention weights\n",
        "\n",
        "            nn.Linear(in_channels, in_channels // reduction),# first linear layer reduces input channels to in_channels // reduction\n",
        "            nn.ReLU(),# second linear layer maps back to the original number of channels\n",
        "            nn.Linear(in_channels // reduction, in_channels),\n",
        "            nn.Sigmoid()  # activation function to generate attention weights\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()# retrieve batch size (b), number of channels (c), height, and width from input tensor\n",
        "        y = self.avg_pool(x).view(b, c)#apply adaptive average pooling to reduce spatial dimensions to 1x1\n",
        "          #apply fully connected layers to generate channel-wise attention weights\n",
        "        y = self.fc(y).view(b, c, 1, 1)  # reshape to (b, c, 1, 1) to match the input tensor shape\n",
        "\n",
        "        # scale the input feature map 'x' by the computed attention weights\n",
        "        return x * y\n"
      ],
      "metadata": {
        "id": "BM7busvzzS7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AGCN Backbone"
      ],
      "metadata": {
        "id": "pIUDd5P007ia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "\n",
        "def kaiming_init(module: nn.Module, #This function performs weight initialization using the Kaiming initialization method. https://towardsdatascience.com/understand-kaiming-initialization-and-implementation-detail-in-pytorch-f7aa967e9138?gi=74574e4cbbbf\n",
        "                 a: float = 0,\n",
        "                 mode: str = 'fan_out',\n",
        "                 nonlinearity: str = 'relu',\n",
        "                 bias: float = 0,\n",
        "                 distribution: str = 'normal') -> None:\n",
        "    # initialization method for weights using Kaiming initialization\n",
        "    assert distribution in ['uniform', 'normal']\n",
        "    if hasattr(module, 'weight') and module.weight is not None:\n",
        "        if distribution == 'uniform':\n",
        "            # kaiming initialization for weights with a uniform distribution\n",
        "            init.kaiming_uniform_(\n",
        "                module.weight, a=a, mode=mode, nonlinearity=nonlinearity)\n",
        "        else:\n",
        "            # kaiming initialization for weights with a normal distribution\n",
        "            init.kaiming_normal_(\n",
        "                module.weight, a=a, mode=mode, nonlinearity=nonlinearity)\n",
        "    if hasattr(module, 'bias') and module.bias is not None:\n",
        "        # constant initialization for bias\n",
        "        init.constant_(module.bias, bias)\n",
        "\n",
        "\n",
        "def constant_init(module: nn.Module, val: float, bias: float = 0) -> None:\n",
        "    # initialization for weights with a constant value\n",
        "    if hasattr(module, 'weight') and module.weight is not None:\n",
        "        init.constant_(module.weight, val)\n",
        "    if hasattr(module, 'bias') and module.bias is not None:\n",
        "        # constant initialization for bias\n",
        "        init.constant_(module.bias, bias)\n",
        "\n",
        "\n",
        "def normal_init(module: nn.Module,\n",
        "                mean: float = 0,\n",
        "                std: float = 1,\n",
        "                bias: float = 0) -> None:\n",
        "    # initialization for weights with a normal distribution\n",
        "    if hasattr(module, 'weight') and module.weight is not None:\n",
        "        init.normal_(module.weight, mean, std)\n",
        "    if hasattr(module, 'bias') and module.bias is not None:\n",
        "        # constant initialization for bias\n",
        "        init.constant_(module.bias, bias)\n",
        "\n",
        "\n",
        "def conv_branch_init(conv, branches):\n",
        "    # initialization for convolutional layer weights based on branches\n",
        "    weight = conv.weight\n",
        "    n = weight.size(0)\n",
        "    k1 = weight.size(1)\n",
        "    k2 = weight.size(2)\n",
        "    # normal initialization for weights with calculated parameters\n",
        "    normal_init(weight, mean=0, std=math.sqrt(2. / (n * k1 * k2 * branches)))\n",
        "    # constant initialization for bias\n",
        "    constant_init(conv.bias, 0)\n",
        "\n",
        "\n",
        "def conv_init(conv):\n",
        "    # kaiming initialization for convolutional layer weights\n",
        "    kaiming_init(conv.weight)\n",
        "    # constant initialization for bias\n",
        "    constant_init(conv.bias, 0)\n",
        "\n",
        "\n",
        "def bn_init(bn, scale):\n",
        "    # constant initialization for BatchNorm layer weights and bias\n",
        "    constant_init(bn.weight, scale)\n",
        "    constant_init(bn.bias, 0)\n",
        "\n",
        "\n",
        "def zero(x):\n",
        "    # Return zero\n",
        "    return 0\n",
        "\n",
        "\n",
        "def identity(x):\n",
        "    # Return the input itself\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "Ml0cq05z2rZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class ConvTemporalGraphical(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 out_channels,\n",
        "                 kernel_size,\n",
        "                 t_kernel_size=1,\n",
        "                 t_stride=1,\n",
        "                 t_padding=0,\n",
        "                 t_dilation=1,\n",
        "                 adj_len=25,\n",
        "                 bias=True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.kernel_size = kernel_size\n",
        "        #initialize a learnable parameter for adjacency matrix\n",
        "        self.PA = nn.Parameter(torch.FloatTensor(5, adj_len, adj_len))\n",
        "        torch.nn.init.constant_(self.PA, 1e-6)  # initialize the parameter to a constant value\n",
        "\n",
        "        self.num_subset = 3  # define the number of subsets\n",
        "        inter_channels = out_channels // 4  # calculate intermediate channels based on output channels\n",
        "        self.inter_c = inter_channels\n",
        "        self.conv_a = nn.ModuleList()  # initialize convolutional layers in ModuleList\n",
        "        self.conv_b = nn.ModuleList()\n",
        "        self.conv_d = nn.ModuleList()\n",
        "        for i in range(self.num_subset):\n",
        "            # append convolutional layers to lists\n",
        "            self.conv_a.append(nn.Conv2d(in_channels, inter_channels, 1))\n",
        "            self.conv_b.append(nn.Conv2d(in_channels, inter_channels, 1))\n",
        "            self.conv_d.append(nn.Conv2d(in_channels, out_channels, 1))\n",
        "\n",
        "        # downsample layer if input channels are not equal to output channels\n",
        "        if in_channels != out_channels:\n",
        "            self.down = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, 1),\n",
        "                nn.BatchNorm2d(out_channels))\n",
        "        else:\n",
        "            self.down = lambda x: x  # identity function if channels are the same\n",
        "\n",
        "        # batch normalization layer, softmax, and ReLU activation\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.soft = nn.Softmax(-2)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # initialize weights and biases for convolutional and batch norm layers\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                conv_init(m)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                bn_init(m, 1)\n",
        "        bn_init(self.bn, 1e-6)\n",
        "        for i in range(self.num_subset):\n",
        "            conv_branch_init(self.conv_d[i], self.num_subset)\n",
        "\n",
        "    def forward(self, x, adj_mat):\n",
        "        \"\"\"Defines the computation performed at every call.\"\"\"\n",
        "        assert adj_mat.size(0) == self.kernel_size  # ensure adjacency matrix size matches kernel size\n",
        "\n",
        "        N, C, T, V = x.size()  # get the dimensions of the input tensor x\n",
        "        A = adj_mat + self.PA  # add the learnable parameter to the adjacency matrix\n",
        "\n",
        "        y = None\n",
        "        for i in range(self.num_subset):\n",
        "            A1 = self.conv_a[i](x).permute(0, 3, 1, 2).contiguous().view(\n",
        "                N, V, self.inter_c * T)  # apply convolution and reshape\n",
        "            A2 = self.conv_b[i](x).view(N, self.inter_c * T, V)  # apply convolution and reshape\n",
        "            A1 = self.soft(torch.matmul(A1, A2) / A1.size(-1))  # apply softmax on the matrix\n",
        "            A1 = A1 + A[i]  # add matrix A[i] to A1\n",
        "            A2 = x.view(N, C * T, V)  # Reshape input x\n",
        "            z = self.conv_d[i](torch.matmul(A2, A1).view(N, C, T, V))  # matrix multiplication and convolution\n",
        "            y = z + y if y is not None else z  # accumulate output results\n",
        "        y = self.bn(y)  # apply batch normalization\n",
        "        y += self.down(x)  # add the result of the downsample layer\n",
        "\n",
        "        return self.relu(y), adj_mat  # apply ReLU activation and return result, adj_mat\n"
      ],
      "metadata": {
        "id": "glRUWrqo2Aol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AGCNBlock(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 out_channels,\n",
        "                 kernel_size,\n",
        "                 stride=1,\n",
        "                 adj_len=25,\n",
        "                 dropout=0,\n",
        "                 residual=True):\n",
        "        super().__init__()\n",
        "\n",
        "        assert len(kernel_size) == 2\n",
        "        assert kernel_size[0] % 2 == 1\n",
        "        padding = ((kernel_size[0] - 1) // 2, 0)\n",
        "\n",
        "        #  Graph convolutional layer\n",
        "        self.gcn = ConvTemporalGraphical(\n",
        "            in_channels, out_channels, kernel_size[1], adj_len=adj_len)\n",
        "\n",
        "        # temporal convolutional layer\n",
        "        self.tcn = nn.Sequential(\n",
        "            nn.Conv2d(out_channels, out_channels, (kernel_size[0], 1),\n",
        "                      (stride, 1), padding), nn.BatchNorm2d(out_channels))\n",
        "\n",
        "        # initialize TCN layers\n",
        "        for m in self.tcn.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                conv_init(m)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                bn_init(m, 1)\n",
        "\n",
        "        # define residual connection / pass or process ? as we talked in the meeting\n",
        "        if not residual:\n",
        "            self.residual = zero  # Function returning zero\n",
        "        elif (in_channels == out_channels) and (stride == 1):\n",
        "            self.residual = identity  # Function returning input itself\n",
        "        else:\n",
        "            self.residual = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    in_channels,\n",
        "                    out_channels,\n",
        "                    kernel_size=1,\n",
        "                    stride=(stride, 1)), nn.BatchNorm2d(out_channels))\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # attention mechanisms (PAM, CAM)\n",
        "        self.att_type = []  # list of attention types\n",
        "        self.attention = len(self.att_type)\n",
        "        if self.attention > 0:\n",
        "            self.channel_attention = ChannelAttention(out_channels)  # channelAttention module\n",
        "\n",
        "    def forward(self, x, adj_mat):\n",
        "        \"\"\"Defines the computation performed at every call.\"\"\"\n",
        "        res = self.residual(x)  # calculate residual connection\n",
        "        x, adj_mat = self.gcn(x, adj_mat)  # graph convolutional layer\n",
        "\n",
        "        # apply attention mechanisms\n",
        "        if self.attention == 1 and self.att_type[0] == 'pam':\n",
        "            x = self.channel_attention(x)\n",
        "            x = self.tcn(x)\n",
        "            x = x + res\n",
        "        elif self.attention == 1 and self.att_type[0] == 'cam':\n",
        "            x = self.tcn(x)\n",
        "            x = self.channel_attention(x)\n",
        "            x = x + res\n",
        "        else:\n",
        "            x = self.tcn(x) + res\n",
        "\n",
        "        if self.attention == 2:\n",
        "            x = self.channel_attention(x)  # apply channel attention\n",
        "\n",
        "        return self.relu(x), adj_mat  # apply ReLU activation and return result, adj_mat\n"
      ],
      "metadata": {
        "id": "BQ-G5eZG1AsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#what are backbone and head in mmaction models ?\n",
        "model = dict(\n",
        "    type='',\n",
        "    backbone=dict(\n",
        "        ),\n",
        "    cls_head=dict(\n",
        "       ),\n",
        "    train_cfg=None,\n",
        "    test_cfg=None)\n",
        "## type:\n",
        "The type parameter defines the type or the class name of the model. It specifies the category or kind of model architecture being used for action recognition. it defines specific architecture type designed for action recognition. The value assigned to type will refer to a specific class or model type within the MMAction framework.\n",
        "##backbone:\n",
        "The backbone parameter defines the architecture or structure of the backbone network used in the model. The backbone network is responsible for feature extraction from input frames or clips. This section typically includes settings such as layer types, number of layers, layer configurations, etc. It refers to the deep models or any other base network architecture used as a feature extractor.\n",
        "##head\n",
        "The cls_head parameter defines the architecture of the classification head. It usually includes fully connected layers or other structures responsible for mapping the extracted features from the backbone into class probabilities or scores. This part is specifically designed for action recognition tasks and is responsible for the final classification or prediction based on the features extracted by the backbone."
      ],
      "metadata": {
        "id": "_P-4Uz0Yi4_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AGCN(nn.Module):\n",
        "    def __init__(self, in_channels, hop_size, strategy, pretrained=None, **kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "        # graph/ the gigantic model before this architecture\n",
        "        self.graph = Graph(hop_size, strategy)\n",
        "        A = torch.tensor(self.graph.A, dtype=torch.float32, requires_grad=False)\n",
        "        self.register_buffer('A', A)\n",
        "        A_size = A.size()\n",
        "\n",
        "        # batch normalization\n",
        "        self.bn = nn.BatchNorm1d(in_channels * A_size[1])\n",
        "\n",
        "        # AGCN Blocks\n",
        "        spatial_kernel_size = A.size(0)\n",
        "        temporal_kernel_size = 9\n",
        "        kernel_size = (temporal_kernel_size, spatial_kernel_size)\n",
        "\n",
        "        # initializing AGCN network with several AGCNBlocks\n",
        "        kwargs0 = {k: v for k, v in kwargs.items() if k != 'dropout'}\n",
        "        self.agcn_networks = nn.ModuleList([\n",
        "            AGCNBlock(in_channels, 64, kernel_size, 1, adj_len=A.size(1), residual=False, **kwargs0),\n",
        "            AGCNBlock(64, 64, kernel_size, 1, adj_len=A.size(1), **kwargs),\n",
        "            AGCNBlock(64, 64, kernel_size, 1, adj_len=A.size(1), **kwargs),\n",
        "            AGCNBlock(64, 64, kernel_size, 1, adj_len=A.size(1), **kwargs),\n",
        "            AGCNBlock(64, 128, kernel_size, 2, adj_len=A.size(1), **kwargs),\n",
        "            AGCNBlock(128, 128, kernel_size, 1, adj_len=A.size(1), **kwargs),\n",
        "            AGCNBlock(128, 128, kernel_size, 1, adj_len=A.size(1), **kwargs),\n",
        "            AGCNBlock(128, 256, kernel_size, 2, adj_len=A.size(1), **kwargs),\n",
        "            AGCNBlock(256, 256, kernel_size, 1, adj_len=A.size(1), **kwargs),\n",
        "            AGCNBlock(256, 256, kernel_size, 1, adj_len=A.size(1), **kwargs),\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        N, C, T, V = x.size()  # batch, channel, frame, node\n",
        "\n",
        "        # data normalization\n",
        "        x = x.permute(0, 3, 1, 2).contiguous().view(N, V * C, T)\n",
        "        x = self.bn(x)\n",
        "        x = x.view(N, V, C, T).permute(0, 2, 3, 1).contiguous()\n",
        "\n",
        "        # looping through AGCN blocks\n",
        "        for gcn in self.agcn_networks:\n",
        "            x, _ = gcn(x, self.A)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "X_7A6mvy3xz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### STGCN head"
      ],
      "metadata": {
        "id": "DuQ8KaTd7nMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class STGCNHead(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_classes,\n",
        "                 in_channels,\n",
        "                 loss_cls=dict(type='CrossEntropyLoss'),\n",
        "                 spatial_type='avg',\n",
        "                 num_person=1,\n",
        "                 init_std=0.01,\n",
        "                 **kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "        self.spatial_type = spatial_type\n",
        "        self.in_channels = in_channels\n",
        "        self.num_classes = num_classes\n",
        "        self.num_person = num_person\n",
        "        self.init_std = init_std\n",
        "\n",
        "        # pooling layer selection based on spatial type\n",
        "        self.pool = None\n",
        "        if self.spatial_type == 'avg':\n",
        "            self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        elif self.spatial_type == 'max':\n",
        "            self.pool = nn.AdaptiveMaxPool2d((1, 1))\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "        # fully connected layer for classification\n",
        "        self.fc = nn.Conv2d(self.in_channels, self.num_classes, kernel_size=1)\n",
        "\n",
        "    def init_weights(self):\n",
        "        # weight initialization for the fully connected layer\n",
        "        normal_init(self.fc, std=self.init_std)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # global pooling\n",
        "        assert self.pool is not None\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.shape[0] // self.num_person, self.num_person, -1, 1, 1).mean(dim=1)\n",
        "\n",
        "        # prediction\n",
        "        x = self.fc(x)\n",
        "        x = x.view(x.shape[0], -1)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "ZQqsN6em7uvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Definition"
      ],
      "metadata": {
        "id": "GdchloFu-wwo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### STGCN"
      ],
      "metadata": {
        "id": "a29cHE29-2Nf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class STGCN(nn.Module):\n",
        "  def __init__(self,\n",
        "               num_classes,\n",
        "               in_channels,\n",
        "               t_kernel_size,\n",
        "               hop_size,\n",
        "               strategy='spatial'):\n",
        "    super().__init__()\n",
        "\n",
        "    self.agcn = AGCN(in_channels, hop_size, strategy)\n",
        "    self.stgcnhead = STGCNHead(num_classes, in_channels=256)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.agcn(x)\n",
        "    x = self.stgcnhead(x)\n",
        "\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "tZceALlx-95n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Loop"
      ],
      "metadata": {
        "id": "3Q3cw9wf0rEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "#---------------------------------------------------------------------------parameters and model\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "\n",
        "NUM_EPOCH = 80\n",
        "BATCH_SIZE = 32\n",
        "CUDA_LAUNCH_BLOCKING=1\n",
        "if(torch.cuda.is_available()):\n",
        "  model = STGCN(num_classes=99,\n",
        "                    in_channels=3,\n",
        "                    t_kernel_size=9,\n",
        "                    hop_size=2).cuda()\n",
        "else:\n",
        "  model = STGCN(num_classes=99,\n",
        "                    in_channels=3,\n",
        "                    t_kernel_size=9,\n",
        "                    hop_size=2)\n",
        "\n",
        "\n",
        "#---------------------------------------------------------------------------optimizer and loss function\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0001, nesterov=True)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "#---------------------------------------------------------------------------here we are defining data and using collator so the model would work error free when facing variant dadta\n",
        "data_loader = dict()\n",
        "collator = MyCollator()\n",
        "data_loader['train'] = torch.utils.data.DataLoader(dataset=Feeder(data=train_data, label=train_label), batch_size=BATCH_SIZE, shuffle=True,collate_fn=collator)\n",
        "data_loader['valid'] = torch.utils.data.DataLoader(dataset=Feeder(data=val_data, label=val_label), batch_size=BATCH_SIZE, shuffle=True,collate_fn=collator)\n",
        "data_loader['test'] = torch.utils.data.DataLoader(dataset=Feeder(data=test_data, label=test_label), batch_size=BATCH_SIZE, shuffle=False,collate_fn=collator)\n",
        "\n",
        "#---------------------------------------------------------------------------training\n",
        "model.train()\n",
        "\n",
        "for epoch in range(1, NUM_EPOCH+1):\n",
        "  correct_train = 0\n",
        "  sum_loss = 0\n",
        "  model.train()\n",
        "  for batch_idx, (data, label) in enumerate(data_loader['train']):\n",
        "    # print(data)\n",
        "    if(torch.cuda.is_available()):\n",
        "      data = data.cuda()\n",
        "      label = torch.LongTensor(label).cuda()\n",
        "    else:\n",
        "      data = data\n",
        "      label = torch.LongTensor(label)\n",
        "\n",
        "#---------------------------------------------------------------------------inference\n",
        "    output = model(data)\n",
        "    # print(len(output),len(label))\n",
        "#---------------------------------------------------------------------------optimization and learning\n",
        "    loss = criterion(output, label)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "#---------------------------------------------------------------------------training metrics\n",
        "    sum_loss += loss.item()\n",
        "    _, predict = torch.max(output.data, 1)\n",
        "    correct_train += (predict == label).sum().item()\n",
        "#---------------------------------------------------------------------------evaluation\n",
        "  model.eval()\n",
        "  val_loss = 0.0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "      for data, label in data_loader['valid']:\n",
        "          if(torch.cuda.is_available()):\n",
        "            data = data.cuda()\n",
        "            label = torch.LongTensor(label).cuda()\n",
        "          else:\n",
        "            data = data\n",
        "            label = torch.LongTensor(label)\n",
        "#---------------------------------------------------------------------------inference\n",
        "          outputs = model(data)\n",
        "#---------------------------------------------------------------------------evaluation metrics\n",
        "          val_loss =criterion(outputs, label)\n",
        "\n",
        "          sum_loss += val_loss.item()\n",
        "          _, predict = torch.max(outputs.data, 1)\n",
        "          correct += (predict == label).sum().item()\n",
        "\n",
        "\n",
        "\n",
        "  print('# Epoch: {} | Train Loss: {:.4f} | Train Accuracy: {:.4f} | Val loss: {:.4f} | Val Accuracy: {:.4f}'.format(epoch, sum_loss/len(data_loader['train'].dataset),(100. * correct_train / len(data_loader['train'].dataset)),val_loss/len(data_loader['valid'].dataset), (100. * correct / len(data_loader['valid'].dataset))))"
      ],
      "metadata": {
        "id": "WeJl8qaXZH6U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4cb70a1-c949-47cd-c183-a0cc003b9aa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Epoch: 1 | Train Loss: 0.1441 | Train Accuracy: 5.1279 | Val loss: 0.0032 | Val Accuracy: 7.3402\n",
            "# Epoch: 2 | Train Loss: 0.1214 | Train Accuracy: 12.9832 | Val loss: 0.0028 | Val Accuracy: 9.3923\n",
            "# Epoch: 3 | Train Loss: 0.1102 | Train Accuracy: 17.1982 | Val loss: 0.0026 | Val Accuracy: 17.2849\n",
            "# Epoch: 4 | Train Loss: 0.1041 | Train Accuracy: 20.2637 | Val loss: 0.0020 | Val Accuracy: 16.2589\n",
            "# Epoch: 5 | Train Loss: 0.0979 | Train Accuracy: 23.5433 | Val loss: 0.0025 | Val Accuracy: 19.8895\n",
            "# Epoch: 6 | Train Loss: 0.0940 | Train Accuracy: 27.7358 | Val loss: 0.0022 | Val Accuracy: 19.5738\n",
            "# Epoch: 7 | Train Loss: 0.0886 | Train Accuracy: 31.7931 | Val loss: 0.0018 | Val Accuracy: 25.8090\n",
            "# Epoch: 8 | Train Loss: 0.0811 | Train Accuracy: 37.5859 | Val loss: 0.0023 | Val Accuracy: 28.8082\n",
            "# Epoch: 9 | Train Loss: 0.0747 | Train Accuracy: 43.4577 | Val loss: 0.0019 | Val Accuracy: 25.4144\n",
            "# Epoch: 10 | Train Loss: 0.0657 | Train Accuracy: 49.3407 | Val loss: 0.0020 | Val Accuracy: 34.4909\n",
            "# Epoch: 11 | Train Loss: 0.0592 | Train Accuracy: 54.7391 | Val loss: 0.0015 | Val Accuracy: 39.7001\n",
            "# Epoch: 12 | Train Loss: 0.0461 | Train Accuracy: 61.9971 | Val loss: 0.0009 | Val Accuracy: 59.5896\n",
            "# Epoch: 13 | Train Loss: 0.0462 | Train Accuracy: 65.0851 | Val loss: 0.0011 | Val Accuracy: 46.6456\n",
            "# Epoch: 14 | Train Loss: 0.0405 | Train Accuracy: 69.6946 | Val loss: 0.0012 | Val Accuracy: 45.7774\n",
            "# Epoch: 15 | Train Loss: 0.0317 | Train Accuracy: 72.6586 | Val loss: 0.0010 | Val Accuracy: 72.9282\n",
            "# Epoch: 16 | Train Loss: 0.0277 | Train Accuracy: 76.3665 | Val loss: 0.0010 | Val Accuracy: 74.9013\n",
            "# Epoch: 17 | Train Loss: 0.0253 | Train Accuracy: 78.7558 | Val loss: 0.0006 | Val Accuracy: 73.2439\n",
            "# Epoch: 18 | Train Loss: 0.0236 | Train Accuracy: 80.7393 | Val loss: 0.0006 | Val Accuracy: 73.2439\n",
            "# Epoch: 19 | Train Loss: 0.0214 | Train Accuracy: 81.1450 | Val loss: 0.0002 | Val Accuracy: 83.0308\n",
            "# Epoch: 20 | Train Loss: 0.0193 | Train Accuracy: 83.4442 | Val loss: 0.0005 | Val Accuracy: 79.0055\n",
            "# Epoch: 21 | Train Loss: 0.0203 | Train Accuracy: 84.9093 | Val loss: 0.0006 | Val Accuracy: 67.6401\n",
            "# Epoch: 22 | Train Loss: 0.0273 | Train Accuracy: 86.7125 | Val loss: 0.0021 | Val Accuracy: 39.8579\n",
            "# Epoch: 23 | Train Loss: 0.0168 | Train Accuracy: 85.5179 | Val loss: 0.0006 | Val Accuracy: 80.1105\n",
            "# Epoch: 24 | Train Loss: 0.0184 | Train Accuracy: 87.8395 | Val loss: 0.0010 | Val Accuracy: 62.5888\n",
            "# Epoch: 25 | Train Loss: 0.0133 | Train Accuracy: 89.4962 | Val loss: 0.0004 | Val Accuracy: 83.8990\n",
            "# Epoch: 26 | Train Loss: 0.0128 | Train Accuracy: 88.9327 | Val loss: 0.0002 | Val Accuracy: 89.0292\n",
            "# Epoch: 27 | Train Loss: 0.0090 | Train Accuracy: 92.3138 | Val loss: 0.0001 | Val Accuracy: 89.2660\n",
            "# Epoch: 28 | Train Loss: 0.0107 | Train Accuracy: 90.7585 | Val loss: 0.0002 | Val Accuracy: 89.4238\n",
            "# Epoch: 29 | Train Loss: 0.0101 | Train Accuracy: 91.2769 | Val loss: 0.0002 | Val Accuracy: 89.9763\n",
            "# Epoch: 30 | Train Loss: 0.0115 | Train Accuracy: 92.5166 | Val loss: 0.0002 | Val Accuracy: 76.0063\n",
            "# Epoch: 31 | Train Loss: 0.0100 | Train Accuracy: 91.2431 | Val loss: 0.0001 | Val Accuracy: 91.8706\n",
            "# Epoch: 32 | Train Loss: 0.0078 | Train Accuracy: 93.3393 | Val loss: 0.0003 | Val Accuracy: 92.1863\n",
            "# Epoch: 33 | Train Loss: 0.0079 | Train Accuracy: 93.5873 | Val loss: 0.0002 | Val Accuracy: 88.8713\n",
            "# Epoch: 34 | Train Loss: 0.0072 | Train Accuracy: 93.7338 | Val loss: 0.0002 | Val Accuracy: 93.0545\n",
            "# Epoch: 35 | Train Loss: 0.0082 | Train Accuracy: 93.6549 | Val loss: 0.0004 | Val Accuracy: 89.3449\n",
            "# Epoch: 36 | Train Loss: 0.0066 | Train Accuracy: 94.4664 | Val loss: 0.0003 | Val Accuracy: 90.9234\n",
            "# Epoch: 37 | Train Loss: 0.0069 | Train Accuracy: 94.8721 | Val loss: 0.0002 | Val Accuracy: 88.3189\n",
            "# Epoch: 38 | Train Loss: 0.0088 | Train Accuracy: 93.4971 | Val loss: 0.0009 | Val Accuracy: 85.0829\n",
            "# Epoch: 39 | Train Loss: 0.0071 | Train Accuracy: 94.1508 | Val loss: 0.0001 | Val Accuracy: 93.1334\n",
            "# Epoch: 40 | Train Loss: 0.0070 | Train Accuracy: 93.9592 | Val loss: 0.0002 | Val Accuracy: 93.6069\n",
            "# Epoch: 41 | Train Loss: 0.0060 | Train Accuracy: 94.7368 | Val loss: 0.0001 | Val Accuracy: 94.3962\n",
            "# Epoch: 42 | Train Loss: 0.0078 | Train Accuracy: 94.8834 | Val loss: 0.0006 | Val Accuracy: 84.8461\n",
            "# Epoch: 43 | Train Loss: 0.0060 | Train Accuracy: 95.0411 | Val loss: 0.0005 | Val Accuracy: 91.9495\n",
            "# Epoch: 44 | Train Loss: 0.0062 | Train Accuracy: 94.5791 | Val loss: 0.0004 | Val Accuracy: 93.0545\n",
            "# Epoch: 45 | Train Loss: 0.0088 | Train Accuracy: 95.0975 | Val loss: 0.0010 | Val Accuracy: 81.7680\n",
            "# Epoch: 46 | Train Loss: 0.0068 | Train Accuracy: 94.7030 | Val loss: 0.0001 | Val Accuracy: 90.8445\n",
            "# Epoch: 47 | Train Loss: 0.0056 | Train Accuracy: 95.4131 | Val loss: 0.0000 | Val Accuracy: 93.2123\n",
            "# Epoch: 48 | Train Loss: 0.0055 | Train Accuracy: 95.6723 | Val loss: 0.0000 | Val Accuracy: 92.9755\n",
            "# Epoch: 49 | Train Loss: 0.0044 | Train Accuracy: 96.4724 | Val loss: 0.0000 | Val Accuracy: 93.4491\n",
            "# Epoch: 50 | Train Loss: 0.0054 | Train Accuracy: 95.5934 | Val loss: 0.0001 | Val Accuracy: 92.4230\n",
            "# Epoch: 51 | Train Loss: 0.0064 | Train Accuracy: 96.2583 | Val loss: 0.0001 | Val Accuracy: 83.4254\n",
            "# Epoch: 52 | Train Loss: 0.0064 | Train Accuracy: 95.4131 | Val loss: 0.0003 | Val Accuracy: 90.8445\n",
            "# Epoch: 53 | Train Loss: 0.0036 | Train Accuracy: 97.1599 | Val loss: 0.0000 | Val Accuracy: 95.5012\n",
            "# Epoch: 54 | Train Loss: 0.0035 | Train Accuracy: 97.4755 | Val loss: 0.0003 | Val Accuracy: 95.4223\n",
            "# Epoch: 55 | Train Loss: 0.0036 | Train Accuracy: 97.1599 | Val loss: 0.0000 | Val Accuracy: 96.1326\n",
            "# Epoch: 56 | Train Loss: 0.0038 | Train Accuracy: 96.8782 | Val loss: 0.0002 | Val Accuracy: 94.6330\n",
            "# Epoch: 57 | Train Loss: 0.0051 | Train Accuracy: 96.0216 | Val loss: 0.0003 | Val Accuracy: 94.6330\n",
            "# Epoch: 58 | Train Loss: 0.0053 | Train Accuracy: 97.1825 | Val loss: 0.0008 | Val Accuracy: 88.7924\n",
            "# Epoch: 59 | Train Loss: 0.0041 | Train Accuracy: 96.9571 | Val loss: 0.0000 | Val Accuracy: 94.4751\n",
            "# Epoch: 60 | Train Loss: 0.0043 | Train Accuracy: 96.7767 | Val loss: 0.0001 | Val Accuracy: 94.7119\n",
            "# Epoch: 61 | Train Loss: 0.0034 | Train Accuracy: 97.2614 | Val loss: 0.0003 | Val Accuracy: 96.3694\n",
            "# Epoch: 62 | Train Loss: 0.0032 | Train Accuracy: 97.7798 | Val loss: 0.0004 | Val Accuracy: 95.4223\n",
            "# Epoch: 63 | Train Loss: 0.0043 | Train Accuracy: 96.9345 | Val loss: 0.0002 | Val Accuracy: 93.7648\n",
            "# Epoch: 64 | Train Loss: 0.0046 | Train Accuracy: 96.7091 | Val loss: 0.0005 | Val Accuracy: 92.6598\n",
            "# Epoch: 65 | Train Loss: 0.0035 | Train Accuracy: 97.2726 | Val loss: 0.0000 | Val Accuracy: 96.2904\n",
            "# Epoch: 66 | Train Loss: 0.0031 | Train Accuracy: 97.6558 | Val loss: 0.0001 | Val Accuracy: 96.1326\n",
            "# Epoch: 67 | Train Loss: 0.0025 | Train Accuracy: 98.4334 | Val loss: 0.0002 | Val Accuracy: 95.2644\n",
            "# Epoch: 68 | Train Loss: 0.0026 | Train Accuracy: 98.1292 | Val loss: 0.0000 | Val Accuracy: 97.1586\n",
            "# Epoch: 69 | Train Loss: 0.0052 | Train Accuracy: 96.9909 | Val loss: 0.0001 | Val Accuracy: 88.0821\n",
            "# Epoch: 70 | Train Loss: 0.0045 | Train Accuracy: 96.8894 | Val loss: 0.0000 | Val Accuracy: 94.8698\n",
            "# Epoch: 71 | Train Loss: 0.0053 | Train Accuracy: 96.0554 | Val loss: 0.0000 | Val Accuracy: 93.4491\n",
            "# Epoch: 72 | Train Loss: 0.0038 | Train Accuracy: 97.3741 | Val loss: 0.0003 | Val Accuracy: 94.1594\n",
            "# Epoch: 73 | Train Loss: 0.0024 | Train Accuracy: 98.6250 | Val loss: 0.0000 | Val Accuracy: 95.5012\n",
            "# Epoch: 74 | Train Loss: 0.0023 | Train Accuracy: 98.1968 | Val loss: 0.0000 | Val Accuracy: 97.5533\n",
            "# Epoch: 75 | Train Loss: 0.0015 | Train Accuracy: 99.1773 | Val loss: 0.0002 | Val Accuracy: 96.6062\n",
            "# Epoch: 76 | Train Loss: 0.0027 | Train Accuracy: 98.2531 | Val loss: 0.0005 | Val Accuracy: 96.3694\n",
            "# Epoch: 77 | Train Loss: 0.0036 | Train Accuracy: 97.6333 | Val loss: 0.0003 | Val Accuracy: 93.9227\n",
            "# Epoch: 78 | Train Loss: 0.0049 | Train Accuracy: 96.0216 | Val loss: 0.0003 | Val Accuracy: 95.2644\n",
            "# Epoch: 79 | Train Loss: 0.0029 | Train Accuracy: 98.2419 | Val loss: 0.0001 | Val Accuracy: 94.4751\n",
            "# Epoch: 80 | Train Loss: 0.0032 | Train Accuracy: 97.7347 | Val loss: 0.0000 | Val Accuracy: 96.0537\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation of Model"
      ],
      "metadata": {
        "id": "UrWow-Hp0yFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio\n",
        "from PIL import Image\n",
        "def prepare_gif_for_model(gif_path,length=300):\n",
        "  gif = imageio.mimread(gif_path)\n",
        "  resized_frames = []\n",
        "  for frame in gif:\n",
        "      image = Image.fromarray(frame)\n",
        "      resized_image = image.resize((25, 25))\n",
        "      resized_frames.append(np.array(resized_image))\n",
        "  frames = np.asarray(resized_frames)\n",
        "  frames = np.transpose(frames, (3, 0, 1, 2))\n",
        "\n",
        "\n",
        "  frames=frames.reshape((3,-1,25)) #check this\n",
        "  if frames.shape[1]>length:\n",
        "      frames= frames[:,:length,:]\n",
        "  data = torch.Tensor(frames)\n",
        "\n",
        "  return np.array(data)"
      ],
      "metadata": {
        "id": "FB1Quw8gMwiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[1].shape"
      ],
      "metadata": {
        "id": "ikMZcnEwM0DY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49094e87-c84c-408b-f255-2282b4a79e82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 119, 25)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#test one file"
      ],
      "metadata": {
        "id": "Im08ErXiM29Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instance=prepare_gif_for_model(\"/content/205_18_0_1_1_stand.txt.gif\")"
      ],
      "metadata": {
        "id": "R3l87jyGM4QI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    if(torch.cuda.is_available()):\n",
        "        data = torch.tensor([instance]).cuda()\n",
        "    else:\n",
        "        data = torch.tensor([instance])\n",
        "\n",
        "    output = model(data)\n",
        "\n",
        "    _, predict = torch.max(output.data, 1)\n",
        "\n",
        "print(predict)"
      ],
      "metadata": {
        "id": "_x9YjT0YM694",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a33adab-8c0f-4dd4-e076-e4c00f6b702b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([6], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-59746615cba0>:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  data = torch.tensor([instance]).cuda()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#test pack of files"
      ],
      "metadata": {
        "id": "8F9gpTAQM_yp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "correct = 0\n",
        "confusion_matrix = np.zeros((100, 100))\n",
        "\n",
        "with torch.no_grad():\n",
        "  for batch_idx, (data, label) in enumerate(data_loader['test']):\n",
        "    if(torch.cuda.is_available()):\n",
        "      data = data.cuda()\n",
        "      label = torch.LongTensor(label).cuda()\n",
        "    else:\n",
        "      data = data\n",
        "      label = torch.LongTensor(label)\n",
        "\n",
        "    output = model(data)\n",
        "\n",
        "    _, predict = torch.max(output.data, 1)\n",
        "    correct += (predict == label).sum().item()\n",
        "\n",
        "    for l, p in zip(label.view(-1), predict.view(-1)):\n",
        "      confusion_matrix[l.long(), p.long()] += 1\n",
        "\n",
        "len_cm = len(confusion_matrix)\n",
        "for i in range(len_cm):\n",
        "    sum_cm = np.sum(confusion_matrix[i])\n",
        "    for j in range(len_cm):\n",
        "        confusion_matrix[i][j] = 100 * (confusion_matrix[i][j] / sum_cm)\n",
        "\n",
        "classes = np.unique(train_label,return_counts=False)\n",
        "plt.imshow(confusion_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title('Confusion matrix')\n",
        "plt.tight_layout()\n",
        "tick_marks = np.arange(len(classes))\n",
        "plt.xticks(tick_marks, classes, rotation=45)\n",
        "plt.yticks(tick_marks, classes)\n",
        "plt.ylabel('True')\n",
        "plt.xlabel('Predicted')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print('# Test Accuracy: {:.3f}[%]'.format(100. * correct / len(data_loader['test'].dataset)))"
      ],
      "metadata": {
        "id": "BE_j3VWqNA8Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "outputId": "7651e6cd-b708-450f-858b-106c75e8fe25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-42adc96eb609>:27: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  confusion_matrix[i][j] = 100 * (confusion_matrix[i][j] / sum_cm)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Test Accuracy: 96.451[%]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Making onnx Models for graphical purpose"
      ],
      "metadata": {
        "id": "ppm-WdM1hlDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q onnx"
      ],
      "metadata": {
        "id": "Hl4TC-X4jJeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_names = [\"Skeleton\"]\n",
        "output_names = [\"Parkinson Prediction\"]\n",
        "\n",
        "stgcn_model = STGCN(num_classes=99,\n",
        "                    in_channels=3,\n",
        "                    t_kernel_size=9,\n",
        "                    hop_size=2)\n",
        "\n",
        "for data, label in data_loader['train']:\n",
        "  x = data\n",
        "  break\n",
        "\n",
        "torch.onnx.export(stgcn_model, x, \"stgcn_model.onnx\", input_names=input_names, output_names=output_names)"
      ],
      "metadata": {
        "id": "nZeY9pPVhwLm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}