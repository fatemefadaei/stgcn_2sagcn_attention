{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDPTa-kcSVF1",
        "outputId": "bb586975-d802-4c58-c53c-9cfb0201f754"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "VQJrMIIWSoXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Use CUDA:', torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONkMTQ9aSqZq",
        "outputId": "4cb78e45-a284-42d4-cff9-9649c5acea23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use CUDA: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 123\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.use_deterministic_algorithms = True"
      ],
      "metadata": {
        "id": "eMIyizmwSsSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reshape_instance(ins):\n",
        "  _,size,_,_=ins.shape\n",
        "  return ins.reshape(3,size,25)\n"
      ],
      "metadata": {
        "id": "gBt9Ozb6SuV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_clip(data , length=300):\n",
        "  for item_iter in range(len(data)):\n",
        "    if data[item_iter].shape[1]>length:\n",
        "      data[item_iter]= data[item_iter][:,:length,:]\n",
        "  return data"
      ],
      "metadata": {
        "id": "I091s8KLSwpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading Dataset pickles"
      ],
      "metadata": {
        "id": "FiwA8CzoS1Bx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q http://mprg.cs.chubu.ac.jp/~itaya/share/mprg_colab/NTU-RGBD_data/data.zip\n",
        "!unzip -q -o data.zip"
      ],
      "metadata": {
        "id": "4JnYhdl_S2bJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('/content/drive/MyDrive/Park/train_3d.pkl', 'rb') as f:\n",
        "    train_data = pickle.load(f)\n",
        "    # train_label = [int(i['label']/10) for i in train_data]\n",
        "    train_label = [i['label'] for i in train_data]\n",
        "    print(train_label[:10])\n",
        "    train_data = [reshape_instance(i['keypoint']) for i in train_data]\n",
        "\n",
        "with open('/content/drive/MyDrive/Park/test_3d.pkl', 'rb') as f:\n",
        "    test_data = pickle.load(f)\n",
        "    # test_label = [int(i['label']/10) for i in test_data]\n",
        "    test_label = [i['label'] for i in test_data]\n",
        "    print(test_label[:10])\n",
        "    test_data = [reshape_instance(i['keypoint']) for i in test_data]\n",
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/Park/val_3d.pkl', 'rb') as f:\n",
        "    val_data = pickle.load(f)\n",
        "    # val_label = [int(i['label']/10) for i in val_data]\n",
        "    val_label = [i['label'] for i in val_data]\n",
        "    print(val_label[:10])\n",
        "    val_data = [reshape_instance(i['keypoint']) for i in val_data]\n",
        "\n",
        "train_data = crop_clip(train_data)\n",
        "test_data = crop_clip(test_data)\n",
        "val_data = crop_clip(val_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hc6OAaWiS-Pp",
        "outputId": "aa622c8d-11cf-40e9-aa3b-9592ab5a77b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[71, 24, 87, 93, 69, 51, 21, 79, 36, 79]\n",
            "[21, 63, 87, 1, 2, 59, 30, 16, 8, 26]\n",
            "[5, 9, 52, 93, 4, 71, 59, 13, 7, 87]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max(train_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4DTQ_o1TBN6",
        "outputId": "447af5ef-b5ce-44fb-8275-47b03d808de1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Defining collator and feeder"
      ],
      "metadata": {
        "id": "dAtm8-jhTGIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import sequence\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "class MyCollator(object):\n",
        "    def __init__(self,test=False,percentile=4750):\n",
        "        self.test = test\n",
        "        self.percentile = percentile\n",
        "    def __call__(self, batch):\n",
        "        # data = [torch.Tensor(item[0]) for item in batch]\n",
        "\n",
        "\n",
        "\n",
        "        # data = pad_sequence(data, padding_value=0)\n",
        "        # target = pad_sequence(target, padding_value=0)\n",
        "        # target = torch.Tensor(target)\n",
        "        # for items in batch:\n",
        "        #   if items[0].shape[1]>300:\n",
        "        #     items[0]= items[0][:,:300,:,:]\n",
        "        max_len = 300\n",
        "        max_len2 = max([x[0].shape[2] for x in batch])\n",
        "\n",
        "        # return [data, target]\n",
        "        batch = sorted(batch, key=lambda x: x[0].shape[1], reverse=True)\n",
        "        target = [item[1] for item in batch]\n",
        "        data = [torch.Tensor(item[0]) for item in batch]\n",
        "        # Pad the sequences to the length of the longest sequence in the batch\n",
        "        # padded_batch = pad_sequence(data, batch_first=True, padding_value=0)\n",
        "        padded_batch = [torch.nn.functional.pad(torch.Tensor(gif[0]), ( 0,0,max_len - gif[0].shape[1], 0)) for gif in batch]\n",
        "        # stack = [[seq[i],label[i]] for i in range(padded_batch.shape[0])]\n",
        "\n",
        "        return [torch.stack(padded_batch),target]\n",
        "\n",
        "class MyCollator_backup(object):\n",
        "    def __init__(self,test=False,percentile=4750):\n",
        "        self.test = test\n",
        "        self.percentile = percentile\n",
        "    def __call__(self, batch):\n",
        "        # data = [torch.Tensor(item[0]) for item in batch]\n",
        "\n",
        "\n",
        "\n",
        "        # data = pad_sequence(data, padding_value=0)\n",
        "        # target = pad_sequence(target, padding_value=0)\n",
        "        # target = torch.Tensor(target)\n",
        "        max_len = max([x[0].shape[1] for x in batch])\n",
        "        max_len2 = max([x[0].shape[2] for x in batch])\n",
        "\n",
        "        # return [data, target]\n",
        "        batch = sorted(batch, key=lambda x: x[0].shape[1], reverse=True)\n",
        "        target = [item[1] for item in batch]\n",
        "        data = [torch.Tensor(item[0]) for item in batch]\n",
        "        # Pad the sequences to the length of the longest sequence in the batch\n",
        "        # padded_batch = pad_sequence(data, batch_first=True, padding_value=0)\n",
        "        padded_batch = [torch.nn.functional.pad(torch.Tensor(gif[0]), ( 0,0,max_len - gif[0].shape[1], 0)) for gif in batch]\n",
        "        # stack = [[seq[i],label[i]] for i in range(padded_batch.shape[0])]\n",
        "\n",
        "        return [torch.stack(padded_batch),target]\n",
        "\n",
        "# def pad_collate(batch):\n",
        "#   data = [item[0] for item in batch]\n",
        "#         target = [item[1] for item in batch]\n",
        "#         target = torch.LongTensor(target)\n",
        "\n",
        "#   xx_pad = pad_sequence(xx, batch_first=True, padding_value=0)\n",
        "#   yy_pad = pad_sequence(yy, batch_first=True, padding_value=0)\n",
        "\n",
        "#   return xx_pad, yy_pad, x_lens, y_lens\n"
      ],
      "metadata": {
        "id": "J2zDKI3sTKQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Feeder(torch.utils.data.Dataset):\n",
        "  def __init__(self, data, label):\n",
        "      super().__init__()\n",
        "      self.label = label\n",
        "      self.data = data\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.label)\n",
        "\n",
        "  def __iter__(self):\n",
        "      return self\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "      data = np.array(self.data[index])\n",
        "      label = self.label[index]\n",
        "\n",
        "      return data, label"
      ],
      "metadata": {
        "id": "JYTgZwtzTM96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Defining Graph to load data in the way ntu+rgb D models give it to action recongnition model"
      ],
      "metadata": {
        "id": "ONm8WUfSTP9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Graph():\n",
        "  def __init__(self, hop_size, strategy):\n",
        "    self.get_edge()\n",
        "\n",
        "    self.hop_size = hop_size\n",
        "    self.hop_dis = self.get_hop_distance(self.num_node, self.edge, hop_size=hop_size)\n",
        "\n",
        "    self.get_adjacency(strategy)\n",
        "\n",
        "  def __str__(self):\n",
        "    return self.A\n",
        "\n",
        "  def get_edge(self):\n",
        "    self.num_node = 25\n",
        "    self_link = [(i, i) for i in range(self.num_node)]\n",
        "    neighbor_base = [(1, 2), (2, 21), (3, 21), (4, 3), (5, 21),\n",
        "                      (6, 5), (7, 6), (8, 7), (9, 21), (10, 9),\n",
        "                      (11, 10), (12, 11), (13, 1), (14, 13), (15, 14),\n",
        "                      (16, 15), (17, 1), (18, 17), (19, 18), (20, 19),\n",
        "                      (22, 23), (23, 8), (24, 25), (25, 12)]\n",
        "    neighbor_link = [(i - 1, j - 1) for (i, j) in neighbor_base]\n",
        "    self.self_link = self_link\n",
        "    self.neighbor_link = neighbor_link\n",
        "    self.edge = self_link + neighbor_link\n",
        "    self.center = 21 - 1\n",
        "\n",
        "  def get_adjacency(self, strategy):\n",
        "    valid_hop = range(0, self.hop_size + 1, 1)\n",
        "    adjacency = np.zeros((self.num_node, self.num_node))\n",
        "    for hop in valid_hop:\n",
        "        adjacency[self.hop_dis == hop] = 1\n",
        "    normalize_adjacency = self.normalize_digraph(adjacency)\n",
        "    if strategy == 'spatial':\n",
        "      A = []\n",
        "      for hop in valid_hop:\n",
        "          a_root = np.zeros((self.num_node, self.num_node))\n",
        "          a_close = np.zeros((self.num_node, self.num_node))\n",
        "          a_further = np.zeros((self.num_node, self.num_node))\n",
        "          for i in range(self.num_node):\n",
        "              for j in range(self.num_node):\n",
        "                  if self.hop_dis[j, i] == hop:\n",
        "                      if self.hop_dis[j, self.center] == self.hop_dis[\n",
        "                              i, self.center]:\n",
        "                          a_root[j, i] = normalize_adjacency[j, i]\n",
        "                      elif self.hop_dis[j, self.center] > self.hop_dis[\n",
        "                              i, self.center]:\n",
        "                          a_close[j, i] = normalize_adjacency[j, i]\n",
        "                      else:\n",
        "                          a_further[j, i] = normalize_adjacency[j, i]\n",
        "          if hop == 0:\n",
        "              A.append(a_root)\n",
        "          else:\n",
        "              A.append(a_root + a_close)\n",
        "              A.append(a_further)\n",
        "      A = np.stack(A)\n",
        "      self.A = A\n",
        "    elif strategy == 'agcn':\n",
        "      A = []\n",
        "      link_mat = self.edge2mat(self.self_link, self.num_node)\n",
        "      In = self.normalize_digraph(self.edge2mat(self.neighbor_link, self.num_node))\n",
        "      outward = [(j, i) for (i, j) in self.neighbor_link]\n",
        "      Out = self.normalize_digraph(self.edge2mat(outward, self.num_node))\n",
        "      A = np.stack((link_mat, In, Out))\n",
        "      self.A = A\n",
        "    else:\n",
        "        raise ValueError('Do Not Exist This Strategy')\n",
        "\n",
        "  def get_hop_distance(self, num_node, edge, hop_size):\n",
        "    A = np.zeros((num_node, num_node))\n",
        "    for i, j in edge:\n",
        "        A[j, i] = 1\n",
        "        A[i, j] = 1\n",
        "    hop_dis = np.zeros((num_node, num_node)) + np.inf\n",
        "    transfer_mat = [np.linalg.matrix_power(A, d) for d in range(hop_size + 1)]\n",
        "    arrive_mat = (np.stack(transfer_mat) > 0)\n",
        "    for d in range(hop_size, -1, -1):\n",
        "        hop_dis[arrive_mat[d]] = d\n",
        "    return hop_dis\n",
        "\n",
        "  def normalize_digraph(self, A):\n",
        "    Dl = np.sum(A, 0)\n",
        "    num_node = A.shape[0]\n",
        "    Dn = np.zeros((num_node, num_node))\n",
        "    for i in range(num_node):\n",
        "        if Dl[i] > 0:\n",
        "            Dn[i, i] = Dl[i]**(-1)\n",
        "    DAD = np.dot(A, Dn)\n",
        "    return DAD\n",
        "\n",
        "  def edge2mat(self, link, num_node):\n",
        "    A = np.zeros((num_node, num_node))\n",
        "    for i, j in link:\n",
        "        A[j, i] = 1\n",
        "    return A"
      ],
      "metadata": {
        "id": "lW8yuzb6TWAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Attention Module class"
      ],
      "metadata": {
        "id": "OLxuk0GpTfW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, in_channels, reduction=16):\n",
        "        super(ChannelAttention, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(in_channels, in_channels // reduction),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_channels // reduction, in_channels),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        y = self.avg_pool(x).view(b, c)\n",
        "        y = self.fc(y).view(b, c, 1, 1)\n",
        "        return x * y"
      ],
      "metadata": {
        "id": "UI30Y7OeThIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##AGCN Backbone"
      ],
      "metadata": {
        "id": "xUfrKoPYTsV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "\n",
        "def kaiming_init(module: nn.Module,\n",
        "                 a: float = 0,\n",
        "                 mode: str = 'fan_out',\n",
        "                 nonlinearity: str = 'relu',\n",
        "                 bias: float = 0,\n",
        "                 distribution: str = 'normal') -> None:\n",
        "    assert distribution in ['uniform', 'normal']\n",
        "    if hasattr(module, 'weight') and module.weight is not None:\n",
        "        if distribution == 'uniform':\n",
        "            nn.init.kaiming_uniform_(\n",
        "                module.weight, a=a, mode=mode, nonlinearity=nonlinearity)\n",
        "        else:\n",
        "            nn.init.kaiming_normal_(\n",
        "                module.weight, a=a, mode=mode, nonlinearity=nonlinearity)\n",
        "    if hasattr(module, 'bias') and module.bias is not None:\n",
        "        nn.init.constant_(module.bias, bias)\n",
        "\n",
        "\n",
        "def constant_init(module: nn.Module, val: float, bias: float = 0) -> None:\n",
        "    if hasattr(module, 'weight') and module.weight is not None:\n",
        "        nn.init.constant_(module.weight, val)\n",
        "    if hasattr(module, 'bias') and module.bias is not None:\n",
        "        nn.init.constant_(module.bias, bias)\n",
        "\n",
        "\n",
        "def normal_init(module: nn.Module,\n",
        "                mean: float = 0,\n",
        "                std: float = 1,\n",
        "                bias: float = 0) -> None:\n",
        "    if hasattr(module, 'weight') and module.weight is not None:\n",
        "        nn.init.normal_(module.weight, mean, std)\n",
        "    if hasattr(module, 'bias') and module.bias is not None:\n",
        "        nn.init.constant_(module.bias, bias)\n",
        "\n",
        "\n",
        "\n",
        "def conv_branch_init(conv, branches):\n",
        "    weight = conv.weight\n",
        "    n = weight.size(0)\n",
        "    k1 = weight.size(1)\n",
        "    k2 = weight.size(2)\n",
        "    normal_init(weight, mean=0, std=math.sqrt(2. / (n * k1 * k2 * branches)))\n",
        "    constant_init(conv.bias, 0)\n",
        "\n",
        "def conv_init(conv):\n",
        "    kaiming_init(conv.weight)\n",
        "    constant_init(conv.bias, 0)\n",
        "\n",
        "def bn_init(bn, scale):\n",
        "    constant_init(bn.weight, scale)\n",
        "    constant_init(bn.bias, 0)\n",
        "\n",
        "\n",
        "def zero(x):\n",
        "    \"\"\"return zero.\"\"\"\n",
        "    return 0\n",
        "\n",
        "\n",
        "def identity(x):\n",
        "    \"\"\"return input itself.\"\"\"\n",
        "    return x"
      ],
      "metadata": {
        "id": "wnRnSOwlUBOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvTemporalGraphical(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 out_channels,\n",
        "                 kernel_size,\n",
        "                 t_kernel_size=1,\n",
        "                 t_stride=1,\n",
        "                 t_padding=0,\n",
        "                 t_dilation=1,\n",
        "                 adj_len=25,\n",
        "                 bias=True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.kernel_size = kernel_size\n",
        "        # 3 for 2sagcn 5 for stgcn\n",
        "        self.PA = nn.Parameter(torch.FloatTensor(5, adj_len, adj_len))\n",
        "        torch.nn.init.constant_(self.PA, 1e-6)\n",
        "\n",
        "        self.num_subset = 3\n",
        "        inter_channels = out_channels // 4\n",
        "        self.inter_c = inter_channels\n",
        "        self.conv_a = nn.ModuleList()\n",
        "        self.conv_b = nn.ModuleList()\n",
        "        self.conv_d = nn.ModuleList()\n",
        "        for i in range(self.num_subset):\n",
        "            self.conv_a.append(nn.Conv2d(in_channels, inter_channels, 1))\n",
        "            self.conv_b.append(nn.Conv2d(in_channels, inter_channels, 1))\n",
        "            self.conv_d.append(nn.Conv2d(in_channels, out_channels, 1))\n",
        "\n",
        "        if in_channels != out_channels:\n",
        "            self.down = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, 1),\n",
        "                nn.BatchNorm2d(out_channels))\n",
        "        else:\n",
        "            self.down = lambda x: x\n",
        "\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.soft = nn.Softmax(-2)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                conv_init(m)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                bn_init(m, 1)\n",
        "        bn_init(self.bn, 1e-6)\n",
        "        for i in range(self.num_subset):\n",
        "            conv_branch_init(self.conv_d[i], self.num_subset)\n",
        "\n",
        "    def forward(self, x, adj_mat):\n",
        "        \"\"\"Defines the computation performed at every call.\"\"\"\n",
        "        assert adj_mat.size(0) == self.kernel_size\n",
        "\n",
        "        N, C, T, V = x.size()\n",
        "        A = adj_mat + self.PA\n",
        "\n",
        "        y = None\n",
        "        for i in range(self.num_subset):\n",
        "            A1 = self.conv_a[i](x).permute(0, 3, 1, 2).contiguous().view(\n",
        "                N, V, self.inter_c * T)\n",
        "            A2 = self.conv_b[i](x).view(N, self.inter_c * T, V)\n",
        "            A1 = self.soft(torch.matmul(A1, A2) / A1.size(-1))  # N V V\n",
        "            A1 = A1 + A[i]\n",
        "            A2 = x.view(N, C * T, V)\n",
        "            z = self.conv_d[i](torch.matmul(A2, A1).view(N, C, T, V))\n",
        "            y = z + y if y is not None else z\n",
        "        y = self.bn(y)\n",
        "        y += self.down(x)\n",
        "\n",
        "        return self.relu(y), adj_mat"
      ],
      "metadata": {
        "id": "DR5t2g9GVuFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AGCNBlock(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 out_channels,\n",
        "                 kernel_size,\n",
        "                 stride=1,\n",
        "                 adj_len=25,\n",
        "                 dropout=0,\n",
        "                 residual=True):\n",
        "        super().__init__()\n",
        "\n",
        "        assert len(kernel_size) == 2\n",
        "        assert kernel_size[0] % 2 == 1\n",
        "        padding = ((kernel_size[0] - 1) // 2, 0)\n",
        "\n",
        "        self.gcn = ConvTemporalGraphical(\n",
        "            in_channels, out_channels, kernel_size[1], adj_len=adj_len)\n",
        "        self.tcn = nn.Sequential(\n",
        "            nn.Conv2d(out_channels, out_channels, (kernel_size[0], 1),\n",
        "                      (stride, 1), padding), nn.BatchNorm2d(out_channels))\n",
        "\n",
        "        # tcn init\n",
        "        for m in self.tcn.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                conv_init(m)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                bn_init(m, 1)\n",
        "\n",
        "        if not residual:\n",
        "            self.residual = zero\n",
        "\n",
        "        elif (in_channels == out_channels) and (stride == 1):\n",
        "            self.residual = identity\n",
        "\n",
        "        else:\n",
        "            self.residual = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    in_channels,\n",
        "                    out_channels,\n",
        "                    kernel_size=1,\n",
        "                    stride=(stride, 1)), nn.BatchNorm2d(out_channels))\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # put list of attention here ['pam', 'cam']\n",
        "        self.att_type = []\n",
        "        self.attention = len(self.att_type)\n",
        "        if self.attention > 0:\n",
        "          self.channel_attention = ChannelAttention(out_channels)\n",
        "\n",
        "    def forward(self, x, adj_mat):\n",
        "        \"\"\"Defines the computation performed at every call.\"\"\"\n",
        "        res = self.residual(x)\n",
        "        x, adj_mat = self.gcn(x, adj_mat)\n",
        "\n",
        "        if self.attention == 1 and self.att_type[0] == 'pam' :\n",
        "          x = self.channel_attention(x)\n",
        "          x = self.tcn(x)\n",
        "          x = x + res\n",
        "        elif self.attention == 1 and self.att_type[0] == 'cam':\n",
        "          x = self.tcn(x)\n",
        "          x = self.channel_attention(x)\n",
        "          x = x + res\n",
        "        else:\n",
        "          x = self.tcn(x) + res\n",
        "\n",
        "        if self.attention == 2:\n",
        "          x = self.channel_attention(x)\n",
        "\n",
        "        return self.relu(x), adj_mat"
      ],
      "metadata": {
        "id": "n1wZchWeVxpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AGCN(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 hop_size,\n",
        "                 strategy,\n",
        "                 pretrained=None,\n",
        "                 **kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "        # load graph\n",
        "        self.graph = Graph(hop_size, strategy)\n",
        "        A = torch.tensor(\n",
        "            self.graph.A, dtype=torch.float32, requires_grad=False)\n",
        "        self.register_buffer('A', A)\n",
        "        A_size = A.size()\n",
        "\n",
        "        # build networks\n",
        "        spatial_kernel_size = A.size(0)\n",
        "        temporal_kernel_size = 9\n",
        "        kernel_size = (temporal_kernel_size, spatial_kernel_size)\n",
        "        self.bn = nn.BatchNorm1d(in_channels * A_size[1])\n",
        "\n",
        "\n",
        "        kwargs0 = {k: v for k, v in kwargs.items() if k != 'dropout'}\n",
        "        self.agcn_networks = nn.ModuleList((\n",
        "            AGCNBlock(\n",
        "                in_channels,\n",
        "                64,\n",
        "                kernel_size,\n",
        "                1,\n",
        "                adj_len=A.size(1),\n",
        "                residual=False,\n",
        "                **kwargs0),\n",
        "            AGCNBlock(64, 64, kernel_size, 1,adj_len=A.size(1), **kwargs),\n",
        "            AGCNBlock(64, 64, kernel_size, 1, adj_len=A.size(1), **kwargs),\n",
        "            AGCNBlock(64, 64, kernel_size, 1,adj_len=A.size(1), **kwargs),\n",
        "            AGCNBlock(64, 128, kernel_size, 2, adj_len=A.size(1), **kwargs),\n",
        "            AGCNBlock(128, 128, kernel_size, 1, adj_len=A.size(1), **kwargs),\n",
        "            AGCNBlock(128, 128, kernel_size, 1, adj_len=A.size(1), **kwargs),\n",
        "            AGCNBlock(128, 256, kernel_size, 2, adj_len=A.size(1), **kwargs),\n",
        "            AGCNBlock(256, 256, kernel_size, 1, adj_len=A.size(1), **kwargs),\n",
        "            AGCNBlock(256, 256, kernel_size, 1, adj_len=A.size(1), **kwargs),\n",
        "        ))\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Defines the computation performed at every call.\n",
        "        Args:\n",
        "            x (torch.Tensor): The input data.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The output of the module.\n",
        "        \"\"\"\n",
        "        # data normalization\n",
        "        N, C, T, V = x.size() # batch, channel, frame, node\n",
        "        x = x.permute(0, 3, 1, 2).contiguous().view(N, V * C, T)\n",
        "        x = self.bn(x)\n",
        "        x = x.view(N, V, C, T).permute(0, 2, 3, 1).contiguous()\n",
        "\n",
        "        for gcn in self.agcn_networks:\n",
        "            x, _ = gcn(x, self.A)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "xa-lF9ajV0sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##STGCN head"
      ],
      "metadata": {
        "id": "h0ayHWDLV5F3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class STGCNHead(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_classes,\n",
        "                 in_channels,\n",
        "                 loss_cls=dict(type='CrossEntropyLoss'),\n",
        "                 spatial_type='avg',\n",
        "                 num_person=1,\n",
        "                 init_std=0.01,\n",
        "                 **kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "        self.spatial_type = spatial_type\n",
        "        self.in_channels = in_channels\n",
        "        self.num_classes = num_classes\n",
        "        self.num_person = num_person\n",
        "        self.init_std = init_std\n",
        "\n",
        "        self.pool = None\n",
        "        if self.spatial_type == 'avg':\n",
        "            self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        elif self.spatial_type == 'max':\n",
        "            self.pool = nn.AdaptiveMaxPool2d((1, 1))\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "        self.fc = nn.Conv2d(self.in_channels, self.num_classes, kernel_size=1)\n",
        "\n",
        "    def init_weights(self):\n",
        "        normal_init(self.fc, std=self.init_std)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # global pooling\n",
        "        assert self.pool is not None\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.shape[0] // self.num_person, self.num_person, -1, 1,\n",
        "                   1).mean(dim=1)\n",
        "\n",
        "        # prediction\n",
        "        x = self.fc(x)\n",
        "        x = x.view(x.shape[0], -1)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "N8diQScXV_U0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Definition"
      ],
      "metadata": {
        "id": "WB1xuVLuWEMy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##STGCN"
      ],
      "metadata": {
        "id": "vFqeSIJ6WK9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class STGCN(nn.Module):\n",
        "  def __init__(self,\n",
        "               num_classes,\n",
        "               in_channels,\n",
        "               t_kernel_size,\n",
        "               hop_size,\n",
        "               strategy='spatial'):\n",
        "    super().__init__()\n",
        "\n",
        "    self.agcn = AGCN(in_channels, hop_size, strategy)\n",
        "    self.stgcnhead = STGCNHead(num_classes, in_channels=256)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.agcn(x)\n",
        "    x = self.stgcnhead(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "-XLHIqn4WF2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##NTU Training"
      ],
      "metadata": {
        "id": "4xvXiw54Wkey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import sequence\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "class NTUCollator(object):\n",
        "    def __init__(self,test=False,percentile=4750):\n",
        "        self.test = test\n",
        "        self.percentile = percentile\n",
        "    def __call__(self, batch):\n",
        "        # data = [torch.Tensor(item[0]) for item in batch]\n",
        "\n",
        "\n",
        "\n",
        "        # data = pad_sequence(data, padding_value=0)\n",
        "        # target = pad_sequence(target, padding_value=0)\n",
        "        # target = torch.Tensor(target)\n",
        "        # for items in batch:\n",
        "        #   if items[0].shape[1]>300:\n",
        "        #     items[0]= items[0][:,:300,:,:]\n",
        "        max_len = 300\n",
        "        max_len2 = max([x[0].shape[2] for x in batch])\n",
        "\n",
        "        # return [data, target]\n",
        "        batch = sorted(batch, key=lambda x: x[0].shape[1], reverse=True)\n",
        "        target = [item[1] for item in batch]\n",
        "        data = [torch.Tensor(item[0]) for item in batch]\n",
        "        # Pad the sequences to the length of the longest sequence in the batch\n",
        "        # padded_batch = pad_sequence(data, batch_first=True, padding_value=0)\n",
        "\n",
        "        padded_batch = [\n",
        "            torch.nn.functional.pad(\n",
        "                torch.Tensor(gif[0]),\n",
        "                (0, 0, max_len - gif[0].shape[1], 0),\n",
        "                value=0  # Specify the padding value if needed\n",
        "            )\n",
        "            for gif in batch\n",
        "        ]\n",
        "\n",
        "        # stack = [[seq[i],label[i]] for i in range(padded_batch.shape[0])]\n",
        "\n",
        "        return [torch.stack(padded_batch),target]\n",
        "\n",
        "\n",
        "class Feeder(torch.utils.data.Dataset):\n",
        "  def __init__(self, data_path, label_path):\n",
        "      super().__init__()\n",
        "      self.label = np.load(label_path)\n",
        "      self.data = np.load(data_path)\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.label)\n",
        "\n",
        "  def __iter__(self):\n",
        "      return self\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "      data = np.array(self.data[index])\n",
        "      label = self.label[index]\n",
        "\n",
        "      return data, label\n",
        "\n",
        "import os\n",
        "\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "\n",
        "NUM_EPOCH = 100\n",
        "BATCH_SIZE = 64\n",
        "CUDA_LAUNCH_BLOCKING=1\n",
        "if(torch.cuda.is_available()):\n",
        "  model = STGCN(num_classes=99,\n",
        "                    in_channels=3,\n",
        "                    t_kernel_size=9,\n",
        "                    hop_size=1).cuda()\n",
        "else:\n",
        "  model = STGCN(num_classes=99,\n",
        "                    in_channels=3,\n",
        "                    t_kernel_size=9,\n",
        "                    hop_size=1)\n",
        "\n",
        "\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0001, nesterov=True)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "data_loader = dict()\n",
        "collator = NTUCollator()\n",
        "data_loader['train'] = torch.utils.data.DataLoader(dataset=Feeder(data_path='data/train_data.npy', label_path='data/train_label.npy'), batch_size=BATCH_SIZE, shuffle=True,collate_fn=collator)\n",
        "data_loader['test'] = torch.utils.data.DataLoader(dataset=Feeder(data_path='data/test_data.npy', label_path='data/test_label.npy'), batch_size=BATCH_SIZE, shuffle=False,collate_fn=collator)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model.train()\n",
        "\n",
        "for epoch in range(1, NUM_EPOCH+1):\n",
        "  correct_train = 0\n",
        "  sum_loss = 0\n",
        "  model.train()\n",
        "  for batch_idx, (data, label) in enumerate(data_loader['train']):\n",
        "    # print(data)\n",
        "    if(torch.cuda.is_available()):\n",
        "      data = data.cuda()\n",
        "      label = torch.LongTensor(label).cuda()\n",
        "    else:\n",
        "      data = data\n",
        "      label = torch.LongTensor(label)\n",
        "    # data=data.reshape(-1,25,300,3)\n",
        "    output = model(data)\n",
        "    # print(len(output),len(label))\n",
        "    loss = criterion(output, label)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    sum_loss += loss.item()\n",
        "    _, predict = torch.max(output.data, 1)\n",
        "    correct_train += (predict == label).sum().item()\n",
        "\n",
        "  model.eval()\n",
        "  val_loss = 0.0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  print('# Epoch: {} | Train Loss: {:.4f} | Train Accuracy: {:.4f} '.format(epoch, sum_loss/len(data_loader['train'].dataset),(100. * correct_train / len(data_loader['train'].dataset))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KF2rwxndWnwi",
        "outputId": "725367c4-16ab-4cda-9832-1b779f62439d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Epoch: 1 | Train Loss: 0.0415 | Train Accuracy: 15.5500 \n",
            "# Epoch: 2 | Train Loss: 0.0344 | Train Accuracy: 20.8000 \n",
            "# Epoch: 3 | Train Loss: 0.0318 | Train Accuracy: 28.0000 \n",
            "# Epoch: 4 | Train Loss: 0.0254 | Train Accuracy: 42.6500 \n",
            "# Epoch: 5 | Train Loss: 0.0186 | Train Accuracy: 59.0000 \n",
            "# Epoch: 6 | Train Loss: 0.0167 | Train Accuracy: 61.3000 \n",
            "# Epoch: 7 | Train Loss: 0.0126 | Train Accuracy: 70.6000 \n",
            "# Epoch: 8 | Train Loss: 0.0118 | Train Accuracy: 74.5500 \n",
            "# Epoch: 9 | Train Loss: 0.0109 | Train Accuracy: 76.5000 \n",
            "# Epoch: 10 | Train Loss: 0.0091 | Train Accuracy: 80.5000 \n",
            "# Epoch: 11 | Train Loss: 0.0089 | Train Accuracy: 80.5500 \n",
            "# Epoch: 12 | Train Loss: 0.0078 | Train Accuracy: 83.8500 \n",
            "# Epoch: 13 | Train Loss: 0.0073 | Train Accuracy: 83.5000 \n",
            "# Epoch: 14 | Train Loss: 0.0063 | Train Accuracy: 86.2000 \n",
            "# Epoch: 15 | Train Loss: 0.0061 | Train Accuracy: 87.1500 \n",
            "# Epoch: 16 | Train Loss: 0.0056 | Train Accuracy: 87.3000 \n",
            "# Epoch: 17 | Train Loss: 0.0054 | Train Accuracy: 87.9000 \n",
            "# Epoch: 18 | Train Loss: 0.0050 | Train Accuracy: 88.4500 \n",
            "# Epoch: 19 | Train Loss: 0.0047 | Train Accuracy: 89.3000 \n",
            "# Epoch: 20 | Train Loss: 0.0049 | Train Accuracy: 88.9000 \n",
            "# Epoch: 21 | Train Loss: 0.0051 | Train Accuracy: 88.7500 \n",
            "# Epoch: 22 | Train Loss: 0.0047 | Train Accuracy: 89.8500 \n",
            "# Epoch: 23 | Train Loss: 0.0043 | Train Accuracy: 90.8000 \n",
            "# Epoch: 24 | Train Loss: 0.0052 | Train Accuracy: 89.2500 \n",
            "# Epoch: 25 | Train Loss: 0.0050 | Train Accuracy: 88.7000 \n",
            "# Epoch: 26 | Train Loss: 0.0040 | Train Accuracy: 90.5500 \n",
            "# Epoch: 27 | Train Loss: 0.0035 | Train Accuracy: 91.9000 \n",
            "# Epoch: 28 | Train Loss: 0.0035 | Train Accuracy: 92.0500 \n",
            "# Epoch: 29 | Train Loss: 0.0029 | Train Accuracy: 94.0000 \n",
            "# Epoch: 30 | Train Loss: 0.0033 | Train Accuracy: 92.7500 \n",
            "# Epoch: 31 | Train Loss: 0.0040 | Train Accuracy: 91.8500 \n",
            "# Epoch: 32 | Train Loss: 0.0036 | Train Accuracy: 92.1500 \n",
            "# Epoch: 33 | Train Loss: 0.0031 | Train Accuracy: 92.9000 \n",
            "# Epoch: 34 | Train Loss: 0.0024 | Train Accuracy: 94.7000 \n",
            "# Epoch: 35 | Train Loss: 0.0022 | Train Accuracy: 95.4500 \n",
            "# Epoch: 36 | Train Loss: 0.0025 | Train Accuracy: 94.3500 \n",
            "# Epoch: 37 | Train Loss: 0.0021 | Train Accuracy: 95.4500 \n",
            "# Epoch: 38 | Train Loss: 0.0026 | Train Accuracy: 94.1500 \n",
            "# Epoch: 39 | Train Loss: 0.0020 | Train Accuracy: 96.0500 \n",
            "# Epoch: 40 | Train Loss: 0.0019 | Train Accuracy: 95.5000 \n",
            "# Epoch: 41 | Train Loss: 0.0018 | Train Accuracy: 95.9500 \n",
            "# Epoch: 42 | Train Loss: 0.0020 | Train Accuracy: 95.9000 \n",
            "# Epoch: 43 | Train Loss: 0.0014 | Train Accuracy: 97.1000 \n",
            "# Epoch: 44 | Train Loss: 0.0020 | Train Accuracy: 96.0500 \n",
            "# Epoch: 45 | Train Loss: 0.0024 | Train Accuracy: 94.0500 \n",
            "# Epoch: 46 | Train Loss: 0.0018 | Train Accuracy: 96.5000 \n",
            "# Epoch: 47 | Train Loss: 0.0016 | Train Accuracy: 96.1000 \n",
            "# Epoch: 48 | Train Loss: 0.0017 | Train Accuracy: 96.4000 \n",
            "# Epoch: 49 | Train Loss: 0.0020 | Train Accuracy: 95.2000 \n",
            "# Epoch: 50 | Train Loss: 0.0015 | Train Accuracy: 96.5000 \n",
            "# Epoch: 51 | Train Loss: 0.0013 | Train Accuracy: 97.1500 \n",
            "# Epoch: 52 | Train Loss: 0.0009 | Train Accuracy: 98.3000 \n",
            "# Epoch: 53 | Train Loss: 0.0010 | Train Accuracy: 97.6000 \n",
            "# Epoch: 54 | Train Loss: 0.0012 | Train Accuracy: 97.6500 \n",
            "# Epoch: 55 | Train Loss: 0.0016 | Train Accuracy: 96.6500 \n",
            "# Epoch: 56 | Train Loss: 0.0015 | Train Accuracy: 97.2500 \n",
            "# Epoch: 57 | Train Loss: 0.0022 | Train Accuracy: 95.8500 \n",
            "# Epoch: 58 | Train Loss: 0.0018 | Train Accuracy: 95.9500 \n",
            "# Epoch: 59 | Train Loss: 0.0013 | Train Accuracy: 97.3500 \n",
            "# Epoch: 60 | Train Loss: 0.0011 | Train Accuracy: 97.6500 \n",
            "# Epoch: 61 | Train Loss: 0.0009 | Train Accuracy: 98.0500 \n",
            "# Epoch: 62 | Train Loss: 0.0009 | Train Accuracy: 98.2500 \n",
            "# Epoch: 63 | Train Loss: 0.0014 | Train Accuracy: 97.1500 \n",
            "# Epoch: 64 | Train Loss: 0.0013 | Train Accuracy: 96.9500 \n",
            "# Epoch: 65 | Train Loss: 0.0008 | Train Accuracy: 98.4500 \n",
            "# Epoch: 66 | Train Loss: 0.0007 | Train Accuracy: 98.4000 \n",
            "# Epoch: 67 | Train Loss: 0.0009 | Train Accuracy: 97.9500 \n",
            "# Epoch: 68 | Train Loss: 0.0005 | Train Accuracy: 98.9000 \n",
            "# Epoch: 69 | Train Loss: 0.0003 | Train Accuracy: 99.5000 \n",
            "# Epoch: 70 | Train Loss: 0.0004 | Train Accuracy: 99.3500 \n",
            "# Epoch: 71 | Train Loss: 0.0008 | Train Accuracy: 98.7000 \n",
            "# Epoch: 72 | Train Loss: 0.0007 | Train Accuracy: 98.5000 \n",
            "# Epoch: 73 | Train Loss: 0.0004 | Train Accuracy: 99.0000 \n",
            "# Epoch: 74 | Train Loss: 0.0004 | Train Accuracy: 99.4000 \n",
            "# Epoch: 75 | Train Loss: 0.0006 | Train Accuracy: 98.7000 \n",
            "# Epoch: 76 | Train Loss: 0.0004 | Train Accuracy: 99.3000 \n",
            "# Epoch: 77 | Train Loss: 0.0010 | Train Accuracy: 98.3500 \n",
            "# Epoch: 78 | Train Loss: 0.0015 | Train Accuracy: 96.7500 \n",
            "# Epoch: 79 | Train Loss: 0.0006 | Train Accuracy: 98.9000 \n",
            "# Epoch: 80 | Train Loss: 0.0003 | Train Accuracy: 99.5000 \n",
            "# Epoch: 81 | Train Loss: 0.0003 | Train Accuracy: 99.5500 \n",
            "# Epoch: 82 | Train Loss: 0.0004 | Train Accuracy: 99.1500 \n",
            "# Epoch: 83 | Train Loss: 0.0009 | Train Accuracy: 98.6500 \n",
            "# Epoch: 84 | Train Loss: 0.0015 | Train Accuracy: 97.2500 \n",
            "# Epoch: 85 | Train Loss: 0.0008 | Train Accuracy: 98.2000 \n",
            "# Epoch: 86 | Train Loss: 0.0006 | Train Accuracy: 98.8500 \n",
            "# Epoch: 87 | Train Loss: 0.0006 | Train Accuracy: 99.0500 \n",
            "# Epoch: 88 | Train Loss: 0.0003 | Train Accuracy: 99.4500 \n",
            "# Epoch: 89 | Train Loss: 0.0003 | Train Accuracy: 99.5000 \n",
            "# Epoch: 90 | Train Loss: 0.0003 | Train Accuracy: 99.5500 \n",
            "# Epoch: 91 | Train Loss: 0.0001 | Train Accuracy: 99.9500 \n",
            "# Epoch: 92 | Train Loss: 0.0002 | Train Accuracy: 99.6500 \n",
            "# Epoch: 93 | Train Loss: 0.0001 | Train Accuracy: 99.9000 \n",
            "# Epoch: 94 | Train Loss: 0.0001 | Train Accuracy: 99.9000 \n",
            "# Epoch: 95 | Train Loss: 0.0002 | Train Accuracy: 99.8500 \n",
            "# Epoch: 96 | Train Loss: 0.0005 | Train Accuracy: 99.1000 \n",
            "# Epoch: 97 | Train Loss: 0.0005 | Train Accuracy: 98.9000 \n",
            "# Epoch: 98 | Train Loss: 0.0004 | Train Accuracy: 99.4000 \n",
            "# Epoch: 99 | Train Loss: 0.0002 | Train Accuracy: 99.7500 \n",
            "# Epoch: 100 | Train Loss: 0.0004 | Train Accuracy: 99.5500 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'ntu_weights.pth')"
      ],
      "metadata": {
        "id": "x8H-nuAUWxDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training Loop"
      ],
      "metadata": {
        "id": "D7FH_DLvWzfq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "USE_WEIGHTS = True\n",
        "NUM_EPOCH = 80\n",
        "BATCH_SIZE = 32\n",
        "CUDA_LAUNCH_BLOCKING=1\n",
        "if(torch.cuda.is_available()):\n",
        "  model = STGCN(num_classes=99,\n",
        "                    in_channels=3,\n",
        "                    t_kernel_size=9,\n",
        "                    hop_size=1).cuda()\n",
        "else:\n",
        "  model = STGCN(num_classes=99,\n",
        "                    in_channels=3,\n",
        "                    t_kernel_size=9,\n",
        "                    hop_size=1)\n",
        "\n",
        "if USE_WEIGHTS:\n",
        "  model.load_state_dict(torch.load('/content/ntu_weights.pth'))\n",
        "\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0001, nesterov=True)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "\n",
        "data_loader = dict()\n",
        "collator = MyCollator()\n",
        "data_loader['train'] = torch.utils.data.DataLoader(dataset=Feeder(data=train_data, label=train_label), batch_size=BATCH_SIZE, shuffle=True,collate_fn=collator)\n",
        "data_loader['valid'] = torch.utils.data.DataLoader(dataset=Feeder(data=val_data, label=val_label), batch_size=BATCH_SIZE, shuffle=True,collate_fn=collator)\n",
        "data_loader['test'] = torch.utils.data.DataLoader(dataset=Feeder(data=test_data, label=test_label), batch_size=BATCH_SIZE, shuffle=False,collate_fn=collator)\n",
        "\n",
        "\n",
        "model.train()\n",
        "\n",
        "for epoch in range(1, NUM_EPOCH+1):\n",
        "  correct_train = 0\n",
        "  sum_loss = 0\n",
        "  model.train()\n",
        "  for batch_idx, (data, label) in enumerate(data_loader['train']):\n",
        "    # print(data)\n",
        "    if(torch.cuda.is_available()):\n",
        "      data = data.cuda()\n",
        "      label = torch.LongTensor(label).cuda()\n",
        "    else:\n",
        "      data = data\n",
        "      label = torch.LongTensor(label)\n",
        "\n",
        "\n",
        "    output = model(data)\n",
        "    # print(len(output),len(label))\n",
        "    loss = criterion(output, label)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    sum_loss += loss.item()\n",
        "    _, predict = torch.max(output.data, 1)\n",
        "    correct_train += (predict == label).sum().item()\n",
        "\n",
        "  model.eval()\n",
        "  val_loss = 0.0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "      for data, label in data_loader['valid']:\n",
        "          if(torch.cuda.is_available()):\n",
        "            data = data.cuda()\n",
        "            label = torch.LongTensor(label).cuda()\n",
        "          else:\n",
        "            data = data\n",
        "            label = torch.LongTensor(label)\n",
        "          outputs = model(data)\n",
        "          val_loss =criterion(outputs, label)\n",
        "\n",
        "          sum_loss += val_loss.item()\n",
        "          _, predict = torch.max(outputs.data, 1)\n",
        "          correct += (predict == label).sum().item()\n",
        "\n",
        "\n",
        "\n",
        "  print('# Epoch: {} | Train Loss: {:.4f} | Train Accuracy: {:.4f} | Val loss: {:.4f} | Val Accuracy: {:.4f}'.format(epoch, sum_loss/len(data_loader['train'].dataset),(100. * correct_train / len(data_loader['train'].dataset)),val_loss/len(data_loader['valid'].dataset), (100. * correct / len(data_loader['valid'].dataset))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njhASaqFW26y",
        "outputId": "ffbf89ea-4f22-41d5-dba4-f4e87ab9ef22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Epoch: 1 | Train Loss: 0.1531 | Train Accuracy: 3.6966 | Val loss: 0.0034 | Val Accuracy: 8.1294\n",
            "# Epoch: 2 | Train Loss: 0.1272 | Train Accuracy: 10.5150 | Val loss: 0.0029 | Val Accuracy: 8.0505\n",
            "# Epoch: 3 | Train Loss: 0.1175 | Train Accuracy: 13.9863 | Val loss: 0.0025 | Val Accuracy: 17.9163\n",
            "# Epoch: 4 | Train Loss: 0.1093 | Train Accuracy: 19.7678 | Val loss: 0.0022 | Val Accuracy: 13.4964\n",
            "# Epoch: 5 | Train Loss: 0.1011 | Train Accuracy: 24.8281 | Val loss: 0.0026 | Val Accuracy: 15.7853\n",
            "# Epoch: 6 | Train Loss: 0.0955 | Train Accuracy: 31.5226 | Val loss: 0.0034 | Val Accuracy: 19.6527\n",
            "# Epoch: 7 | Train Loss: 0.0783 | Train Accuracy: 39.6033 | Val loss: 0.0018 | Val Accuracy: 36.5430\n",
            "# Epoch: 8 | Train Loss: 0.0671 | Train Accuracy: 48.8674 | Val loss: 0.0019 | Val Accuracy: 40.9629\n",
            "# Epoch: 9 | Train Loss: 0.0541 | Train Accuracy: 56.2155 | Val loss: 0.0011 | Val Accuracy: 54.2226\n",
            "# Epoch: 10 | Train Loss: 0.0573 | Train Accuracy: 62.2112 | Val loss: 0.0023 | Val Accuracy: 25.7301\n",
            "# Epoch: 11 | Train Loss: 0.0488 | Train Accuracy: 67.8125 | Val loss: 0.0028 | Val Accuracy: 30.4657\n",
            "# Epoch: 12 | Train Loss: 0.0411 | Train Accuracy: 72.9178 | Val loss: 0.0037 | Val Accuracy: 38.5162\n",
            "# Epoch: 13 | Train Loss: 0.0269 | Train Accuracy: 78.7220 | Val loss: 0.0007 | Val Accuracy: 68.9818\n",
            "# Epoch: 14 | Train Loss: 0.0200 | Train Accuracy: 83.7034 | Val loss: 0.0009 | Val Accuracy: 80.3473\n",
            "# Epoch: 15 | Train Loss: 0.0187 | Train Accuracy: 86.6900 | Val loss: 0.0011 | Val Accuracy: 71.2707\n",
            "# Epoch: 16 | Train Loss: 0.0137 | Train Accuracy: 87.8959 | Val loss: 0.0009 | Val Accuracy: 89.1871\n",
            "# Epoch: 17 | Train Loss: 0.0147 | Train Accuracy: 90.0823 | Val loss: 0.0014 | Val Accuracy: 70.5604\n",
            "# Epoch: 18 | Train Loss: 0.0104 | Train Accuracy: 91.9757 | Val loss: 0.0001 | Val Accuracy: 87.0560\n",
            "# Epoch: 19 | Train Loss: 0.0104 | Train Accuracy: 93.9930 | Val loss: 0.0002 | Val Accuracy: 77.8216\n",
            "# Epoch: 20 | Train Loss: 0.0071 | Train Accuracy: 94.2184 | Val loss: 0.0001 | Val Accuracy: 93.2123\n",
            "# Epoch: 21 | Train Loss: 0.0074 | Train Accuracy: 93.8916 | Val loss: 0.0001 | Val Accuracy: 91.8706\n",
            "# Epoch: 22 | Train Loss: 0.0058 | Train Accuracy: 95.2440 | Val loss: 0.0007 | Val Accuracy: 93.3702\n",
            "# Epoch: 23 | Train Loss: 0.0052 | Train Accuracy: 96.2358 | Val loss: 0.0000 | Val Accuracy: 93.2123\n",
            "# Epoch: 24 | Train Loss: 0.0048 | Train Accuracy: 96.6528 | Val loss: 0.0003 | Val Accuracy: 92.5809\n",
            "# Epoch: 25 | Train Loss: 0.0109 | Train Accuracy: 97.2501 | Val loss: 0.0016 | Val Accuracy: 62.5888\n",
            "# Epoch: 26 | Train Loss: 0.0042 | Train Accuracy: 96.7091 | Val loss: 0.0000 | Val Accuracy: 95.4223\n",
            "# Epoch: 27 | Train Loss: 0.0034 | Train Accuracy: 97.6107 | Val loss: 0.0001 | Val Accuracy: 94.7119\n",
            "# Epoch: 28 | Train Loss: 0.0023 | Train Accuracy: 98.5912 | Val loss: 0.0001 | Val Accuracy: 95.7380\n",
            "# Epoch: 29 | Train Loss: 0.0043 | Train Accuracy: 98.4334 | Val loss: 0.0002 | Val Accuracy: 87.3717\n",
            "# Epoch: 30 | Train Loss: 0.0042 | Train Accuracy: 98.2306 | Val loss: 0.0001 | Val Accuracy: 87.6085\n",
            "# Epoch: 31 | Train Loss: 0.0052 | Train Accuracy: 96.3147 | Val loss: 0.0001 | Val Accuracy: 92.5809\n",
            "# Epoch: 32 | Train Loss: 0.0044 | Train Accuracy: 96.6753 | Val loss: 0.0005 | Val Accuracy: 95.6590\n",
            "# Epoch: 33 | Train Loss: 0.0039 | Train Accuracy: 97.8249 | Val loss: 0.0002 | Val Accuracy: 89.8185\n",
            "# Epoch: 34 | Train Loss: 0.0030 | Train Accuracy: 97.5769 | Val loss: 0.0000 | Val Accuracy: 97.2376\n",
            "# Epoch: 35 | Train Loss: 0.0028 | Train Accuracy: 99.0871 | Val loss: 0.0003 | Val Accuracy: 91.2391\n",
            "# Epoch: 36 | Train Loss: 0.0019 | Train Accuracy: 98.7828 | Val loss: 0.0000 | Val Accuracy: 97.4743\n",
            "# Epoch: 37 | Train Loss: 0.0033 | Train Accuracy: 98.0052 | Val loss: 0.0001 | Val Accuracy: 92.2652\n",
            "# Epoch: 38 | Train Loss: 0.0027 | Train Accuracy: 98.3658 | Val loss: 0.0003 | Val Accuracy: 96.6062\n",
            "# Epoch: 39 | Train Loss: 0.0017 | Train Accuracy: 99.0533 | Val loss: 0.0000 | Val Accuracy: 97.3954\n",
            "# Epoch: 40 | Train Loss: 0.0014 | Train Accuracy: 99.2900 | Val loss: 0.0000 | Val Accuracy: 97.5533\n",
            "# Epoch: 41 | Train Loss: 0.0009 | Train Accuracy: 99.6506 | Val loss: 0.0002 | Val Accuracy: 97.6322\n",
            "# Epoch: 42 | Train Loss: 0.0016 | Train Accuracy: 99.7971 | Val loss: 0.0002 | Val Accuracy: 92.8177\n",
            "# Epoch: 43 | Train Loss: 0.0033 | Train Accuracy: 98.0728 | Val loss: 0.0004 | Val Accuracy: 93.8437\n",
            "# Epoch: 44 | Train Loss: 0.0041 | Train Accuracy: 97.1487 | Val loss: 0.0004 | Val Accuracy: 95.6590\n",
            "# Epoch: 45 | Train Loss: 0.0038 | Train Accuracy: 98.1292 | Val loss: 0.0003 | Val Accuracy: 88.8713\n",
            "# Epoch: 46 | Train Loss: 0.0058 | Train Accuracy: 95.2553 | Val loss: 0.0000 | Val Accuracy: 95.3433\n",
            "# Epoch: 47 | Train Loss: 0.0038 | Train Accuracy: 97.4191 | Val loss: 0.0000 | Val Accuracy: 94.1594\n",
            "# Epoch: 48 | Train Loss: 0.0031 | Train Accuracy: 97.8361 | Val loss: 0.0000 | Val Accuracy: 95.7380\n",
            "# Epoch: 49 | Train Loss: 0.0069 | Train Accuracy: 99.6281 | Val loss: 0.0013 | Val Accuracy: 71.0339\n",
            "# Epoch: 50 | Train Loss: 0.0044 | Train Accuracy: 96.6077 | Val loss: 0.0000 | Val Accuracy: 96.2115\n",
            "# Epoch: 51 | Train Loss: 0.0012 | Train Accuracy: 99.3463 | Val loss: 0.0000 | Val Accuracy: 97.7111\n",
            "# Epoch: 52 | Train Loss: 0.0009 | Train Accuracy: 99.8309 | Val loss: 0.0002 | Val Accuracy: 97.1586\n",
            "# Epoch: 53 | Train Loss: 0.0005 | Train Accuracy: 99.9211 | Val loss: 0.0000 | Val Accuracy: 97.8690\n",
            "# Epoch: 54 | Train Loss: 0.0005 | Train Accuracy: 99.9549 | Val loss: 0.0002 | Val Accuracy: 97.5533\n",
            "# Epoch: 55 | Train Loss: 0.0006 | Train Accuracy: 99.8986 | Val loss: 0.0000 | Val Accuracy: 97.7901\n",
            "# Epoch: 56 | Train Loss: 0.0005 | Train Accuracy: 99.9436 | Val loss: 0.0000 | Val Accuracy: 98.2636\n",
            "# Epoch: 57 | Train Loss: 0.0006 | Train Accuracy: 99.9211 | Val loss: 0.0000 | Val Accuracy: 97.4743\n",
            "# Epoch: 58 | Train Loss: 0.0007 | Train Accuracy: 99.9324 | Val loss: 0.0003 | Val Accuracy: 97.3954\n",
            "# Epoch: 59 | Train Loss: 0.0007 | Train Accuracy: 99.8084 | Val loss: 0.0000 | Val Accuracy: 97.9479\n",
            "# Epoch: 60 | Train Loss: 0.0009 | Train Accuracy: 99.6732 | Val loss: 0.0000 | Val Accuracy: 96.9219\n",
            "# Epoch: 61 | Train Loss: 0.0124 | Train Accuracy: 95.7286 | Val loss: 0.0021 | Val Accuracy: 58.5635\n",
            "# Epoch: 62 | Train Loss: 0.0052 | Train Accuracy: 96.2921 | Val loss: 0.0003 | Val Accuracy: 93.6069\n",
            "# Epoch: 63 | Train Loss: 0.0046 | Train Accuracy: 96.8444 | Val loss: 0.0002 | Val Accuracy: 92.7388\n",
            "# Epoch: 64 | Train Loss: 0.0039 | Train Accuracy: 96.8331 | Val loss: 0.0002 | Val Accuracy: 96.6851\n",
            "# Epoch: 65 | Train Loss: 0.0021 | Train Accuracy: 98.5574 | Val loss: 0.0000 | Val Accuracy: 97.2376\n",
            "# Epoch: 66 | Train Loss: 0.0011 | Train Accuracy: 99.6055 | Val loss: 0.0002 | Val Accuracy: 97.3165\n",
            "# Epoch: 67 | Train Loss: 0.0020 | Train Accuracy: 98.8279 | Val loss: 0.0001 | Val Accuracy: 96.2115\n",
            "# Epoch: 68 | Train Loss: 0.0009 | Train Accuracy: 99.6281 | Val loss: 0.0000 | Val Accuracy: 97.6322\n",
            "# Epoch: 69 | Train Loss: 0.0010 | Train Accuracy: 99.5943 | Val loss: 0.0000 | Val Accuracy: 96.8429\n",
            "# Epoch: 70 | Train Loss: 0.0013 | Train Accuracy: 99.4365 | Val loss: 0.0000 | Val Accuracy: 97.1586\n",
            "# Epoch: 71 | Train Loss: 0.0010 | Train Accuracy: 99.6844 | Val loss: 0.0000 | Val Accuracy: 97.5533\n",
            "# Epoch: 72 | Train Loss: 0.0012 | Train Accuracy: 99.4590 | Val loss: 0.0001 | Val Accuracy: 97.0797\n",
            "# Epoch: 73 | Train Loss: 0.0015 | Train Accuracy: 99.4703 | Val loss: 0.0001 | Val Accuracy: 95.7380\n",
            "# Epoch: 74 | Train Loss: 0.0025 | Train Accuracy: 98.6701 | Val loss: 0.0000 | Val Accuracy: 96.0537\n",
            "# Epoch: 75 | Train Loss: 0.0032 | Train Accuracy: 98.2306 | Val loss: 0.0002 | Val Accuracy: 93.7648\n",
            "# Epoch: 76 | Train Loss: 0.0017 | Train Accuracy: 99.1322 | Val loss: 0.0002 | Val Accuracy: 96.5272\n",
            "# Epoch: 77 | Train Loss: 0.0075 | Train Accuracy: 98.0052 | Val loss: 0.0013 | Val Accuracy: 68.4294\n",
            "# Epoch: 78 | Train Loss: 0.0050 | Train Accuracy: 96.3259 | Val loss: 0.0001 | Val Accuracy: 94.5541\n",
            "# Epoch: 79 | Train Loss: 0.0034 | Train Accuracy: 98.1066 | Val loss: 0.0008 | Val Accuracy: 93.6069\n",
            "# Epoch: 80 | Train Loss: 0.0034 | Train Accuracy: 98.2531 | Val loss: 0.0001 | Val Accuracy: 92.8966\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluation of Model"
      ],
      "metadata": {
        "id": "WQoBFFZhXIK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "def prepare_gif_for_model(gif_path,length=300):\n",
        "  gif = imageio.mimread(gif_path)\n",
        "  resized_frames = []\n",
        "  for frame in gif:\n",
        "      image = Image.fromarray(frame)\n",
        "      resized_image = image.resize((25, 25))\n",
        "      resized_frames.append(np.array(resized_image))\n",
        "  frames = np.asarray(resized_frames)\n",
        "  frames = np.transpose(frames, (3, 0, 1, 2))\n",
        "\n",
        "\n",
        "  frames=frames.reshape((3,-1,25)) #check this\n",
        "  if frames.shape[1]>length:\n",
        "      frames= frames[:,:length,:]\n",
        "  data = torch.Tensor(frames)\n",
        "\n",
        "  return np.array(data)"
      ],
      "metadata": {
        "id": "MbTXv9XFXN0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DqOaAFzXP6i",
        "outputId": "1b586826-96d3-4ea5-eef2-cfa1369b26ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 119, 25)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##test one file"
      ],
      "metadata": {
        "id": "XpjFcyUxXSZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instance=prepare_gif_for_model(\"/content/205_18_0_1_1_stand.txt.gif\")"
      ],
      "metadata": {
        "id": "jBUmC17gXXaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    if(torch.cuda.is_available()):\n",
        "        data = torch.tensor([instance]).cuda()\n",
        "    else:\n",
        "        data = torch.tensor([instance])\n",
        "\n",
        "    output = model(data)\n",
        "\n",
        "    _, predict = torch.max(output.data, 1)\n",
        "\n",
        "print(predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MawF8ce9Xzti",
        "outputId": "537763de-1655-4f79-cbd4-ca749486837d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-48-59746615cba0>:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  data = torch.tensor([instance]).cuda()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##test pack of files"
      ],
      "metadata": {
        "id": "IYWA--f1X2R6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "correct = 0\n",
        "confusion_matrix = np.zeros((100, 100))\n",
        "\n",
        "with torch.no_grad():\n",
        "  for batch_idx, (data, label) in enumerate(data_loader['test']):\n",
        "    if(torch.cuda.is_available()):\n",
        "      data = data.cuda()\n",
        "      label = torch.LongTensor(label).cuda()\n",
        "    else:\n",
        "      data = data\n",
        "      label = torch.LongTensor(label)\n",
        "\n",
        "    output = model(data)\n",
        "\n",
        "    _, predict = torch.max(output.data, 1)\n",
        "    correct += (predict == label).sum().item()\n",
        "\n",
        "    for l, p in zip(label.view(-1), predict.view(-1)):\n",
        "      confusion_matrix[l.long(), p.long()] += 1\n",
        "\n",
        "len_cm = len(confusion_matrix)\n",
        "for i in range(len_cm):\n",
        "    sum_cm = np.sum(confusion_matrix[i])\n",
        "    for j in range(len_cm):\n",
        "        confusion_matrix[i][j] = 100 * (confusion_matrix[i][j] / sum_cm)\n",
        "\n",
        "classes = np.unique(train_label,return_counts=False)\n",
        "plt.imshow(confusion_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title('Confusion matrix')\n",
        "plt.tight_layout()\n",
        "tick_marks = np.arange(len(classes))\n",
        "plt.xticks(tick_marks, classes, rotation=45)\n",
        "plt.yticks(tick_marks, classes)\n",
        "plt.ylabel('True')\n",
        "plt.xlabel('Predicted')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print('# Test Accuracy: {:.3f}[%]'.format(100. * correct / len(data_loader['test'].dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "id": "l8PTFvCfX7sK",
        "outputId": "ea4ff0fe-b934-411f-ef3a-d5c4c3a21835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-49-42adc96eb609>:27: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  confusion_matrix[i][j] = 100 * (confusion_matrix[i][j] / sum_cm)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Test Accuracy: 93.139[%]\n"
          ]
        }
      ]
    }
  ]
}